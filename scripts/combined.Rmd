---
title: "Fgrandis_ad/intr"
author: "Elias"
date: "May 11, 2018"
output: html_document
---

#Fundulus grandis adapting to contamination

##Uploading files to NCBI

```{r}
library(XML)
library(tidyr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(RCurl)
library(ggplot2)
library(reshape2)

```

* Downloaded .bam files to computer
```{bash}
#log into NIH
ftp ftp-private.ncbi.nlm.nih.gov
#Go to directory
cd uploads/oziolor@gmail.com_4XM4FcAt/new_folder
#turn off interactive mode so it doesn't ask you to submit each freaking sample
prompt
#Submit all samples
mput BU*
```

##installing ANGSD
* low coverage data neutral statistics

```{bash Installing ANGSD}
#[cluster]:/data/oziolore/program/
#Installing angsd

wget http://popgen.dk/software/download/angsd/angsd0.920.tar.gz
tar xf angsd0.920.tar.gz
cd htslib;make;cd ..
cd angsd
make HTSSRC=../htslib
cd ..

```

## Took 10Mb of random regions throughout the genome and plotted coverage over them to decide what is an over-represented site threshold

```{bash Exploring high coverage}
#Getting coverage over all bases in the genome [cluster]
#starting with a merged bam of all individuals

samtools depth \
-d 10000 /home/oziolore/restoreFromData/fhet/data/align/all_merged.bam |\
gzip > /home/oziolore/restoreFromData/fhet/data/coverage/coverage_allbases.txt.gz

#Converting the high coverage data to bed file format [cluster]

zcat /home/oziolore/restoreFromData/fhet/data/coverage/coverage_allbases.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>300){print}}' | \
bedtools merge -i - -d 10 -c 4 -o count > /home/oziolore/restoreFromData/fhet/data/coverage/hicov.bed

#Getting 10Mb of random regions to makea decision on [cluster]

#!/bin/bash
dir=/home/oziolore/restoreFromData/fhet/data/coverage

zcat $dir/coverage_allbases.txt.gz | \
sort -R | \
head -n 10000000 | \
gzip > $dir/cov_10Mbrand.txt.gz

#used the following line to create a genome file in the /genome2/ subfolder
awk -v OFS='\t' {'print $1,$2'} $fai > $genome

```

## Downloading that to personal computer to use r and make decision on the threshold for high coverage

```{bash Copying coverage to computer}
#downloading from cluster
scp kodiak:/data/oziolore/fhet/data/coverage/cov_10Mbrand.txt.gz /home/elias/analysis/data/angsd/
```

```{r deciding on a threshold of high coverage}
setwd("~/analysis/data/admixture/")
cov<-read.table("~/analysis/data/angsd/cov_10Mbrand.txt.gz",header=F) #reading in output of 10Mb random bases selected
colnames(cov)<-c("chrom","pos","coverage") #assigning names to columns of data

hist(cov$coverage,breaks=1000)
hist(cov$coverage,breaks=1000,xlim=c(0,300))

subw<-cov$cov<200
hist(cov[subw,"coverage"],breaks=1000)
summary(cov$cov)
summary(cov[subw,"coverage"])

#Qualitatively I will throw out sites above 200x coverage

```

## applying filter for high coverage sites to genome file in order to only keep normal coverage ones

```{bash Creating a high coverage file excluding those SNPs}
#using awk and bedtools merge, I am using
zcat /data/oziolore/fhet/data/coverage2/coverage_allbases2.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>200){print}}' | \
/data/oziolore/program/bedtools2/bin/bedtools merge -i - -d 10 -c 4 -o count > /data/oziolore/fhet/data/coverage2/hicov.bed

#Downloading data to look at how much of the genome I threw out
scp kodiak:/data/oziolore/fhet/data/coverage2/hicov.bed /home/elias/analysis/data/angsd/
```

```{r looking at size of excluded high coverage regions}
hi<-read.table("~/analysis/data/angsd/hicov.bed",header=FALSE)
sum(hi[,4])

#Threw out 52Mb of data => 5% of the genome
```

## Creating a keepsites file with all bases that have below 200x coverage

```{bash Create the keepsites file and export to computer}
#[cluster]

zcat /data/oziolore/fhet/data/coverage2/coverage_allbases2.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4<200){print}}' | \
bedtools merge -i - -d 10 > /data/oziolore/fhet/data/angsd2/keepsites2.bed

#Converting those to a .file format for ANGSD to deal with
cat /data/oziolore/fhet/data/angsd2/keepsites2.bed | \
awk '{OFS="\t"}{s=$2+1}{print $1,s,$3}' > /data/oziolore/fhet/data/angsd2/keepsites2.file

#Downloading the .bed file to make a script with 50Mb randomly selected to create expectation for SFS

scp kodiak:/data/oziolore/fhet/data/angsd2/keepsites2.bed ~/analysis/data/angsd/

```

## Script to pick up 50Mb at random from the keepsites file in order to run SAF and SFS on those for bayesian priors

```{r Selecting random 50Mb from it}

orig<-read.table("~/analysis/data/angsd/keepsites2.bed", header=F) #reading in the keepsites file

p<-(orig[,3]-orig[,2])/(sum(orig[,3]-orig[,2])) #creating probability vector so that I don't oversample large chunks

p<-unlist(p) #unlisting the vector

z<-p<0 #removing any negative probabilities for 0 values
p<-p[!z] #applying that to vector

v<-sample(x=length(p),size=11500,prob=p) #sampling 11500 chunks with probability to get out ~50Mb of the genome
v<-sort(v)
sum(orig[v,3]-orig[v,2]) #checking the total size of bases

write.table(orig[v,], file="~/analysis/data/angsd/keep50Mb.bed",row.names=FALSE,col.names=FALSE,quote=FALSE)
```

## putting that data back into [cluster]

```{bash Copy those selections to computer}
scp /home/elias/analysis/data/angsd/keep50Mb.bed kodiak:/data/oziolore/fhet/data/angsd2/

```

## Converting that to a .file

```{bash Convert from bed to file}
cat /data/oziolore/fhet/data/angsd2/keep50Mb.bed | \
awk '{OFS="\t"}{s=$2+1}{print $1,s,$3}' > /data/oziolore//fhet/data/angsd2/keep50Mb.file
```

## indexing all of those files with ANGSD

```{bash Index keepsites}
/data/oziolore/program/angsd/angsd sites index /data/oziolore/fhet/data/angsd2/keepsites2.file
/data/oziolore/program/angsd/angsd sites index /data/oziolore/fhet/data/angsd2/keep50Mb.file
```

## fixing up lists of all populations .bam files so they can be plugged into ANGSD

```{bash Fix lists in order to reflect correct directory}
cat BB2.txt | sed 's/home/data/' | sed 's/restoreFromData\///' | uniq > BB2_new.txt
```

## Starting site allele frequency estimation on a 50Mb subsample for each population (to create SFS)

```{bash Running Site Allele Frequency estimations on the 50Mb chunk}

#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#files
list=/data/oziolore/fhet/data/list2/$one\2_new.txt
genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta
keep=/data/oziolore/fhet/data/angsd2/keep50Mb.file
outfile=/data/oziolore/fhet/data/angsd2/$one\_small
my_angsd=/data/oziolore/program/angsd/angsd

$my_angsd \
-bam $list \
-doSaf 1 \
-fold 1 \
-anc $genome \
-GL 2 \
-minMapQ 30 \
-minQ 20 \
-minind 10 \
-sites $keep \
-out $outfile

```

## Using the subsampled .saf to create site frequency spectra

```{bash Running Site Frequency Statistic on the 50Mb chunk}


#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')


#program and file
my_sfs=/data/oziolore/program/angsd_norm/misc/realSFS
in_saf=/data/oziolore/fhet/data/angsd2/$one\_small.saf.idx
outdir=/data/oziolore/fhet/data/angsd2
out_sfs=$one\.sfs

#code

$my_sfs $in_saf -maxIter 100 -P 8 -nSites 50000000 > $outdir/$out_sfs


```

##Creating site allele frequencies for full genome of each population

```{bash Full SAF/Not necessary step}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#files
list=/data/oziolore/fhet/data/list2/$one\2_new.txt
genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta
keep=/data/oziolore/fhet/data/angsd2/keepsites2.file
outfile=/data/oziolore/fhet/data/angsd2/$one\_full
my_angsd=/data/oziolore/program/angsd/angsd

$my_angsd \
-bam $list \
-doSaf 1 \
-fold 1 \
-anc $genome \
-GL 2 \
-minMapQ 30 \
-minQ 20 \
-minind 10 \
-sites $keep \
-out $outfile
```

##Once saf and sfs are created, take sfs to R to look at distribution

```{bash Copy SFS to computer to plot}
scp kodiak:/data/oziolore/fhet/data/angsd2/*.sfs /home/elias/analysis/data/angsd/raw/
```

##Plot SFS in R
* starting with folded spectra of subsample (24 per population)

```{r Plot subsampled SFS}
sf<-list.files("~/analysis/data/angsd/subsample/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* unfolded spectra of subsample (24 per population)

```{r Plot unfolded subsampled SFS}
sf<-list.files("~/analysis/data/angsd/subsample/unfolded/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* folded spectra of all individuals

```{r Plot full sample SFS}
sf<-list.files("~/analysis/data/angsd/raw/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* unfolded spectra of all individuals

```{r Plot full sample unfolded SFS}
sf<-list.files("~/analysis/data/angsd/raw/unfolded/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

##-doThetas seqfault error again
* that has been throwing segfaults left and right for different people.
* fix is to change lines in abcSaf.cpp that have:
r->pLikes[myCounter] =new float[numInds+1]
to
r->pLikes[myCounter] =new float[2*numInds+1]
* will only use for folded frequency spectra estimations. For unfolded, leave original in /program/angsd_norm/angsd

##Everything works fine on -doSaf unfolded spectra

##Re-do of SFS for 1 pop (looks like crap)

```{bash Re-do of crappy SFS}
#!/bin/bash

#program and file
my_sfs=/data/oziolore/program/angsd_norm/misc/realSFS
in_saf=/data/oziolore/fhet/data/angsd2/BB_small.saf.idx
outdir=/data/oziolore/fhet/data/angsd2
out_sfs=BB.sfs

#code

$my_sfs $in_saf -maxIter 100 -P 8 -nSites 50000000 > $outdir/$out_sfs

```

##Reading thetas.gz file to a readable state: below is command for folded estimate of subsample

```{bash Making the thetas estimates into a readable file}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=24:00:00
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')


#program/file
my_stat=/data/oziolore/program/angsd_norm/misc/thetaStat
file=/data/oziolore/fhet/data/angsd2/theta/subsample/$one\.theta.thetas.idx
out=/data/oziolore/fhet/data/angsd2/theta/subsample/$one\_readable_theta.gz

$my_stat print $file | gzip > $out
```

* SP has some issues in one of the characters in the compressed readable version. re-doing
    + worked after just repeating script
    
* Breaking them into sliding windows

```{bash Sliding windows from Noah's lift file UPDATE THIS WITH HOW YOU CREATED THE WINDOWS}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=02:00:00
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#programs and files

my_bedtools=/data/oziolore/program/bedtools2/bin/bedtools
thetas=/data/oziolore/fhet/data/angsd2/theta/$one\_readable_theta.gz
window=/data/oziolore/fhet/data/windows2/new_noah.1kb.bed
my_genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta.fai
outdir=/data/oziolore/fhet/data/angsd2/theta          
outfile=$one\_neut_1kb.bed

zcat $thetas | \
egrep -v "^#" | \
awk '{OFS="\t"}{w=exp($3)}{pi=exp($4)}{s=$2-1}{print $1,s,$2,w,pi}' | \
$my_bedtools map \
-a $window \
-b stdin \
-g <(cut -f 1-2 $my_genome) \
-c 4,4,5,5 \
-o sum,count,sum,count > $outdir/$outfile

```
    
## Plotting distribution of neutral estimates (full sample size)
* starting with folded samples

```{bash Copy those files into computer}
scp kodiak:/data/oziolore/fhet/data/angsd2/theta/*_1kb* /home/elias/analysis/data/angsd/raw/

```

* Break the file into pi, theta and and calculate tajima's D
* starting with 1kb windows by noah's lift file. Merging them into 20 kb windows

```{r First data wrangling with R}
###Buffalo Bayou loding pi(column6), theta(column4), and counts(columns 5,7)

bb<-read.table("~/analysis/data/angsd/raw/BB_neut_1kb.bed",stringsAsFactors=FALSE) #reading in all files
vb<-read.table("~/analysis/data/angsd/raw/VB_neut_1kb.bed",stringsAsFactors=FALSE)
pb<-read.table("~/analysis/data/angsd/raw/PB_neut_1kb.bed",stringsAsFactors=FALSE)
sj<-read.table("~/analysis/data/angsd/raw/SJ_neut_1kb.bed",stringsAsFactors=FALSE)
bnp<-read.table("~/analysis/data/angsd/raw/BNP_neut_1kb.bed",stringsAsFactors=FALSE)
sp<-read.table("~/analysis/data/angsd/raw/SP_neut_1kb.bed",stringsAsFactors=FALSE)
gb<-read.table("~/analysis/data/angsd/raw/GB_neut_1kb.bed",stringsAsFactors=FALSE)

colnam<-c("scaf","Start","End","Theta","Tcount","Pi","Pcount") #giving them column names
colnames(bb)<-colnam
colnames(vb)<-colnam
colnames(pb)<-colnam
colnames(sj)<-colnam
colnames(bnp)<-colnam
colnames(sp)<-colnam
colnames(gb)<-colnam

#Calculating mean pi from 1kb non-overlapping windows----
pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames

cov<-cbind(bb[1:3],bb[,7],vb[,7],pb[,7],sj[,7],bnp[,7],sp[,7],gb[,7]) #creating a vector of coverage of each statistic call

for(i in popnames){
  for(j in 4:7){
  pops[[i]][,j]<-as.numeric(pops[[i]][,j])
  }
}


###Calculating blocks of certianty
nsnps<-cov[,4] #creating a vector that sums all calls over each SNP
for (i in 5:10){
  nsnps <- nsnps + cov[,i]
}
nsnps <- nsnps/7 #dividing by number of populations and only using sites that have at least 20 SNPS used over the window per population

subw <- nsnps > 50 #filter to be saved for these windows

#calculating mean and median pi----
pimean<-c() #calculating mean/something is wrong here. check
for(i in popnames){
  pimean[i]<-sum(pops[[i]][subw,6],na.rm=TRUE)/sum(pops[[i]][subw,7],na.rm=TRUE)
}

#calculating effective population size
#Theta(pi)=4Ne*u => Ne=theta(pi)/4u

u1<-3.5e-9 #mutation rate from cichlids
u2<-1.5e-9 #mutation rate from flounder
u3<-2.2e-9 #average eukaryotic mutation rate

mut<-c(u1,u2,u3)

Ne<-matrix(nrow=7,ncol=3)
rownames(Ne)<-names(pimean)
colnames(Ne)<-c("cichlid u","flounder u","euk u")
  
for(i in 1:3){
  Ne[,i]<-as.numeric(pimean/(4*mut[i]))
}

write.table(Ne,"~/analysis/data/angsd/Ne_estimates.csv",quote=FALSE)

#Slide function----
#This basically takes width number of windows and takes an average pi of them
slide<-function(x,y,width,slide){
  aver<-c()
  for(i in 1:length(y)){
    count=1
    if(is.na(y[i])){added=0}else{added<-y[i]}
    for(j in 1:(width-1)){
      index<-sum(i,j)
      if(is.na(x[index,1])){next()}
      if(is.na(y[index])){next()}
      if(x[index-1,1]==x[index,1]){
        added=added+y[index]
        count=count+1
      }else{next()}
    }
    aver[i]<-added
  }
  return(aver)
}

#Slidecount function----
slidecount<-function(x,y,width,slide){
  count<-c()
  for(i in 1:length(y)){
    if(is.na(y[i])){added=0}else{added<-y[i]}
    for(j in 1:(width-1)){
      index<-sum(i,j)
      if(is.na(x[index,1])){next()}
      if(is.na(y[index])){next()}
      if(x[index-1,1]==x[index,1]){
        added=added+y[index]
      }else{next()}
    }
    count[i]<-added
  }
  return(count)
}

pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames
pops2<-pops

for(i in popnames){ #converting files into 20kb merged windows
  for(j in c(4,6)){
    print(i)
    pops2[[i]][,j]<-slide(pops[[i]],as.numeric(pops[[i]][,j]),width=20,slide=1)
  }
  for(f in c(5,7)){
    print(i)
    pops2[[i]][,f]<-slidecount(pops[[i]],as.numeric(pops[[i]][,f]),width=20,slide=1)
  }
}


write.table(pops2[["bb"]],"~/analysis/data/angsd/raw/BB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["vb"]],"~/analysis/data/angsd/raw/VB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["pb"]],"~/analysis/data/angsd/raw/PB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["sj"]],"~/analysis/data/angsd/raw/SJ_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["bnp"]],"~/analysis/data/angsd/raw/BNP_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["sp"]],"~/analysis/data/angsd/raw/SP_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["gb"]],"~/analysis/data/angsd/raw/GB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")

```

*Let's read in the windowed estimates we just created

```{r}

bb<-read.csv("~/analysis/data/angsd/raw/BB_neut2.bed",stringsAsFactors=FALSE) #reading in all files
vb<-read.csv("~/analysis/data/angsd/raw/VB_neut2.bed",stringsAsFactors=FALSE)
pb<-read.csv("~/analysis/data/angsd/raw/PB_neut2.bed",stringsAsFactors=FALSE)
sj<-read.csv("~/analysis/data/angsd/raw/SJ_neut2.bed",stringsAsFactors=FALSE)
bnp<-read.csv("~/analysis/data/angsd/raw/BNP_neut2.bed",stringsAsFactors=FALSE)
sp<-read.csv("~/analysis/data/angsd/raw/SP_neut2.bed",stringsAsFactors=FALSE)
gb<-read.csv("~/analysis/data/angsd/raw/GB_neut2.bed",stringsAsFactors=FALSE)

colnam<-c("scaf","Start","End","Theta","Tcount","Pi","Pcount") #giving them column names
colnames(bb)<-colnam
colnames(vb)<-colnam
colnames(pb)<-colnam
colnames(sj)<-colnam
colnames(bnp)<-colnam
colnames(sp)<-colnam
colnames(gb)<-colnam

pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames

cov<-cbind(bb[1:3],bb[,7],vb[,7],pb[,7],sj[,7],bnp[,7],sp[,7],gb[,7]) #creating a vector of coverage of each statistic call

for(i in popnames){
  for(j in 4:7){
  pops[[i]][,j]<-as.numeric(pops[[i]][,j])
  }
}


###Calculating blocks of certianty
nsnps<-cov[,4] #creating a vector that sums all calls over each SNP
for (i in 5:10){
  nsnps <- nsnps + cov[,i]
}
nsnps <- nsnps/7 #dividing by number of populations and only using sites that have at least 20 SNPS used over the window per population

subw <- nsnps > 50 #filter to be saved for these windows

#calculating mean and median pi----
pimean<-c() #calculating mean/something is wrong here. check
for(i in popnames){
  pimean[i]<-sum(pops[[i]][subw,6],na.rm=TRUE)/sum(pops[[i]][subw,7],na.rm=TRUE)
}

popbase<-list()

for(i in popnames){ #calculating per base estimates rather than averaged estimates over the windows we have
  popbase[[i]]<-cbind(pops[[i]][,1:3],pops[[i]][,4]/pops[[i]][,5],pops[[i]][,6]/pops[[i]][,7])
}

names<-c("scaf", "start","end",'theta/b',"pi/b")

for(i in popnames){ #giving the new list column names
  colnames(popbase[[i]])<-names
}

wt<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of Waterson's theta values
for(i in 1:7){
  wt[,i]<-popbase[[i]][,4]
}
colnames(wt)<-popnames

pi<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of pi values
for(i in 1:7){
  pi[,i]<-popbase[[i]][,5]
}
colnames(pi)<-popnames


source("~/analysis/scripts/angsd/tajimas.r")

###Before calculating statistics I want to merge these into 5kb windows with 1kb slide.

taj<-list()

for(i in popnames){ #calculating tajima's D for all populations through a function in r; takes forever
  print(i)
  for(j in 1:dim(pi)[[1]]){
    taj[[i]]<-c(taj[[i]],tajimas(pi[j,i],wt[j,i],24))
  }
}


taj<-cbind(popbase[[1]][,1:3],taj[["bb"]],taj[["vb"]],taj[["pb"]],taj[["sj"]],taj[["bnp"]],taj[["sp"]],taj[["gb"]]) #binding into a dataframe

taj<-cbind(taj,keep=as.numeric(subw)) #keeping the filter of low representation bases

tajname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep") #column names
colnames(taj)<-tajname

write.csv(taj,file="~/analysis/data/angsd/taj",quote=FALSE,row.names=FALSE) #writing tajima's d

theta<-cbind(popbase[["bb"]][1:3],wt,keep=as.numeric(subw))

thetname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep")
colnames(theta)<-thetname

write.csv(theta,file="~/analysis/data/angsd/thetas",quote=FALSE,row.names=FALSE)


pi<-cbind(popbase[["bb"]][1:3],pi,keep=as.numeric(subw))

piname<-c("scaf","start","end","bb","vb","pb","sj","bnp","sp","gb","keep")
colnames(pi)<-piname
write.csv(pi,file="~/analysis/data/angsd/pi",quote=FALSE,row.names=FALSE)

write.csv(cov,file="~/analysis/data/angsd/cov",quote=FALSE,row.names = FALSE)

```

```{r}
library('tidyr')
library('tibble')
library('magrittr')
library('dplyr')

#loading neutrality stats----

theta<-read.table("~/analysis/data/angsd/thetas",header=TRUE, sep=',') #reading in summary statistics
pi<-read.table("~/analysis/data/angsd/pi", header=TRUE, sep=',')
taj<-read.table("~/analysis/data/angsd/taj",header=TRUE, sep=',')

subw<-pi[,"keep"]>0 #applying filter of low coverage

##ggplot pi----
library(ggplot2)
library(reshape2)

mpi<-melt(pi[,1:10],id=c("scaf","start","end"))

ggplot(mpi,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(0,.015))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))

mtaj<-melt(taj[,1:10],id=c("scaf","start","end"))

ggplot(mtaj,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(-.35,.1))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))

#visualizing pi distribution----

bbp<-density(pi[subw,4],na.rm=TRUE)
vbp<-density(pi[subw,5],na.rm=TRUE)
pbp<-density(pi[subw,6],na.rm=TRUE)
sjp<-density(pi[subw,7],na.rm=TRUE)
bnpp<-density(pi[subw,8],na.rm=TRUE)
spp<-density(pi[subw,9],na.rm=TRUE)
gbp<-density(pi[subw,10],na.rm=TRUE)

par(mfrow=c(2,1),mar=c(4,5,2,2),mgp=c(3,2,0))

plot(gbp,xlim=c(0.0001,.025),col="cadetblue3",bty="l",ylim=c(0,450),
     cex.lab=2,xlab="",ylab="",lwd=3,main="",cex.axis=3)
#polygon(gbp,col="cadetblue1",density=100,border=NA)
lines(spp,xlim=c(0.001,.025),col="cadetblue3",lwd=3)
#polygon(spp,col="cadetblue3",density=100,border=NA)
lines(bnpp,xlim=c(0.001,.025),col="firebrick2",lwd=3)
#polygon(bnpp,col="lightpink",density=100,border=NA)
lines(sjp,xlim=c(0.001,.025),col="firebrick2",lwd=3)
#polygon(sjp,col="firebrick2",density=100,border=NA)
lines(pbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(pbp,col="grey80",density=100,border=NA)
lines(vbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(vbp,col="grey40",density=100,border=NA)
lines(bbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(bbp,col="black",density=100,border=NA)



box(lwd=7,bty="l")

#visualizing tajima's D distribution----

bbtaj<-density(taj[subw,4],na.rm=TRUE)
vbtaj<-density(taj[subw,5],na.rm=TRUE)
pbtaj<-density(taj[subw,6],na.rm=TRUE)
sjtaj<-density(taj[subw,7],na.rm=TRUE)
bnptaj<-density(taj[subw,8],na.rm=TRUE)
sptaj<-density(taj[subw,9],na.rm=TRUE)
gbtaj<-density(taj[subw,10],na.rm=TRUE)

#par(mfrow=c(1,1),mgp=c(3,2,0))
plot(bnptaj,xlim=c(-.3,.3),col="firebrick2",bty="l",
     ylim=c(0,50),xlab="",ylab="",main="",lwd=3,cex.axis=4)
#polygon(bnptaj,col="lightpink",density=100,border=NA)
lines(sjtaj,xlim=c(-.15,.3),col="firebrick2",lwd=3)
#polygon(sjtaj,col="red",density=100,border=NA)
lines(pbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(pbtaj,col="grey80",density=100,border=NA)
lines(vbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(vbtaj,col="grey40",density=100,border=NA)
lines(bbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(bbtaj,col="black",density=100,border=NA)
#polygon(sptaj,col="cadetblue3",density=100,border=NA)
lines(sptaj,xlim=c(-.15,.3),col="cadetblue3",lwd=3)
lines(gbtaj,xlim=c(-.15,.3),col="cadetblue3",lwd=3)
#polygon(gbtaj,col="cadetblue1",density=100,border=NA)

box(lwd=7,bty="l")

# 
# #####Plotting theta vs pi----
# 
# par(mfrow=c(3,3))
# plot(theta[,4],pi[,4],pch=20,cex=.5,col="black")
# abline(a=0,b=1,col="red")
# plot(theta[,5],pi[,5],pch=20,cex=.5,col="grey")
# abline(a=0,b=1,col="red")
# plot(theta[,6],pi[,6],pch=20,cex=.5,col="red")
# abline(a=0,b=1,col="black")
# plot(theta[,7],pi[,7],pch=20,cex=.5,col="orange")
# abline(a=0,b=1,col="red")
# plot(theta[,8],pi[,8],pch=20,cex=.5,col="yellow")
# abline(a=0,b=1,col="red")
# plot(theta[,9],pi[,9],pch=20,cex=.5,col="green")
# abline(a=0,b=1,col="red")
# plot(theta[,10],pi[,10],pch=20,cex=.5,col="blue")
# abline(a=0,b=1,col="red")
```


##Genome-wide Fst plot from Hudson's Fst
* Calculating genome wide Hudson statistic

```{r}
library(XML)
library(magrittr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(stringr)
library(dplyr)
library(gtools)
library(RColorBrewer)
library(lattice)
library(gplots)

load("~/analysis/data/comparison/noah_stats.RData")
subw<-val[,4]>0
neutsum<-colSums(fst[subw,4:94],na.rm=TRUE) #summing up columns of pi and dxy statistics
snpsum<-sum(val[subw,4])
neutbase<-neutsum/snpsum

pops<-c("BB","VB","PB","SJSP","BNP","SP","GB")

fsth<-matrix(nrow = 7,ncol=7) #creating matrix to hold fst data
rownames(fsth)<- pops
colnames(fsth)<- pops

for(i in pops){
  for(j in pops){
    if(i==j){next()}
    fsth[i,j]<-1-((neutbase[i]+neutbase[j])/2)/neutbase[paste(sort(unique(c(i,j))),collapse=".")]
  }
}

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/fstgenomewide.jpeg",width=600,height=600)
levelplot(fsth,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8,
          pretty=FALSE,cex=2) #Better plot than above
dev.off()

#Including Fh Pops

pops2<-c("BB","VB","PB","SJSP","BNP","SP","GB","ER","KC","NYC","F")

fsth2<-matrix(nrow = 11,ncol=11) #creating matrix to hold fst data
rownames(fsth2)<- pops2
colnames(fsth2)<- pops2

for(i in pops2){
  for(j in pops2){
    if(i==j){next()}
    fsth2[i,j]<-1-((neutbase[i]+neutbase[j])/2)/neutbase[paste(sort(unique(c(i,j))),collapse=".")]
  }
}

levelplot(fsth2,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8,
          pretty=FALSE,cex=2) #Better plot than above

write.csv(fsth2,"~/analysis/data/fst/fhet_gran_fst.csv")
```

##Calculating Hudson's Fst from pi and dxy

```{r}
load("~/analysis/data/comparison/noah_stats.RData") #loading data produced from individual SNP call pi and dxy calculations

pops<-c("BB","VB","PB","SJSP","BNP","GB","SP") #creating a vector of names for our populations

fsth<-as.data.frame(fst2[,1:21])#creating matrix to hold fst data takes about 1 hour to run; Here I'm calculating Hudson's Fst from our dataset;

f=0
for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(i>j){next()}
    f<-f+1
    print(f)
    colnames(fsth)[f]<-paste(sort(unique(c(i,j))),collapse=".")
    print(colnames(fsth)[f])
    fsth[,f]<-1-((fst2[,i]+fst2[,j])/2)/fst2[,paste(sort(unique(c(i,j))),collapse=".")]
  }
}

#write.table(fsth,"~/analysis/data/fst/fsth",col.names = FALSE,quote = FALSE,row.names = FALSE) #to save it for later

#fsth<-read.table("~/analysis/data/fst/fsth",header=FALSE) #loading fsth values
```
##Caclulating Z statistic from the fst values

```{r}
#Dependent on having loaded fsth into RAM from above chunk
# install.packages('matrixStats')
library(matrixStats)

fsth[!is.finite(as.matrix(fsth))]<-NA #making all inifite values into NA

fstmeans<-colMeans(fsth,na.rm=TRUE) #calculating average fst
fstmeans<-as.matrix(fstmeans) #putting it into a matrix

fststdev<-colSds(as.matrix(fsth),na.rm=TRUE) #calculating standard deviation overall
fststdev<-as.matrix(fststdev)
row.names(fststdev)<-row.names(fstmeans) #making sure the rows are correctly assigned

zfst<-matrix(nrow=dim(fsth)[1],ncol=dim(fsth)[2]) #creating a matrix that will hold z values
colnames(zfst)<-colnames(fsth)

#running a loop that calculates z values
for (i in 1:21){
    zfst[,i]<-(fsth[,i]-fstmeans[i])/fststdev[i]
}

#write.table(zfst,"~/analysis/data/fst/zfst_hud_1kb",row.names=FALSE,col.names=FALSE,quote=FALSE,sep="\t")
#zfst<-read.table("~/analysis/data/fst/zfst_hud_1kb",header=FALSE)
```

##Subtraction of pi and conversion to z statistic CORRECT THIS TO BE THE PI VALUES YOU JUST CALCULATED FROM ANGSD

```{r}
pi<-read.csv("~/analysis/data/angsd/pi",stringsAsFactors=TRUE) #taking only pi values for F. grandis from dataframe
pops<-c("bb","vb","pb","sj","bnp","sp","gb") #creating a vector of names for our populations

head(val) # vector of # of SNPs evaluated to come to a summary statistic per window

fsth2<-cbind(lift,fsth) #getting the coordinates onto the fsth matrix

pidiff<-as.data.frame(fst[-1,1:21]) #creating data frame that would hold pidiff values; my calculated pi values have 1 less row (first row of chr1 from 0-1000); don't know why, but oh well. suck it row 0-1000

#looping over variables to calculate the difference in pi
f=0
for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(i>j){next()}
    f<-f+1
    print(f)
    colnames(pidiff)[f]<-paste(sort(unique(c(i,j))),collapse=".")
    print(colnames(pidiff)[f])
    pidiff[,f]<-pi[,i]-pi[,j]
  }
}

pidiff[!is.finite(as.matrix(pidiff))]<-NA #removing all infinite values and replacing with NA
pimeans<-colMeans(as.matrix(pidiff),na.rm=TRUE) #calculating means of columns of pi difference
pimeans<-as.matrix(pimeans) #converting into a matrix so I can use numeric values out of it

library(matrixStats)
pistdev<-colSds(as.matrix(pidiff),na.rm=TRUE) #calculating standard deviation from columns
pistdev<-as.matrix(pistdev)

zpi<-matrix(nrow=dim(pidiff)[[1]],ncol = dim(pidiff)[[2]])

for (i in 1:21){
    zpi[,i]<-(pidiff[,i]-pimeans[i])/pistdev[i]
}
colnames(zpi)<-colnames(pidiff)

#write.table(zpi,"~/analysis/data/angsd/zpi_20kb",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
```

##Messing around with pi

```{r}
library('reshape')
library(ggplot2)

mpi<-melt(pi[,4:10])

ggplot(mpi,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(0,.017))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))


```

## Merging z statistics into a common one (high z would mean high fst and low pi)

```{r}
#zfst<-read.table("~/analysis/data/fst/zfst_hud_1kb",sep='\t')
#zpi<-read.table("~/analysis/data/angsd/zpi_1kb",sep="\t")
colnames(zfst)<-colnames(fsth) #naming columns
colnames(zpi)<-colnames(fsth)

zfst<-as.data.frame(zfst)
zpi<-as.data.frame(zpi)

zfst2<-zfst %>% mutate(seq=seq(1:dim(zfst)[[1]])) #adding sequence, basically a way to match the rows to each other
zpi2<-zpi %>% mutate(seq=seq(1:dim(zpi)[[1]])) #same

colnam<-colnames(zfst2[,1:21]) #saving colnames as a vector so we can match columns
zmerge_temp<-cbind(zfst2[colnam]-zpi2[match(zfst2$seq,zpi2$seq),colnam]) #subtracting zpi from zfst for a zmerge

subw<-val[,4]>5 #filtering values that didn't have very many supportive snps

zmerge<-zmerge_temp %>% mutate(keep=as.numeric(subw)) #Adds that filter column as 0s and 1s

#write.table(zmerge,"~/analysis/data/dfst/zmerge_1kb",row.names = FALSE,col.names = FALSE,quote = FALSE)

```

## Doing a PBS analysis with Z statistics

```{r}
#zmerge<-read.table("~/analysis/data/dfst/zmerge_1kb",header=FALSE)

znames<-c(names(fsth),"keep")
colnames(zmerge)<-znames

names(zmerge)<-gsub("SJSP","SJ",names(zmerge))

distgb<-zmerge %>% 
  select(contains("GB")) #only selecting GB columns
sub1<-gsub("GB.","",names(distgb)) #removing GB from names
sub2<-gsub(".GB","",sub1)
names(distgb)<-sub2

distsp<-zmerge %>% 
  select(contains("SP")) #only selecting SP columns
sub3<-gsub("SP.","",names(distsp))
sub4<-gsub(".SP","",sub3)
names(distsp)<-sub4

pops<-c("BB","VB","PB","SJ","BNP")

distgb2<-distgb %>% 
  select(pops) #rearranging columns

distsp2<-distsp %>% 
  select(pops)

colnam<-colnames(distgb2) #assigning a vector
distsp3<-distsp2 %>% mutate(seq=seq(1:dim(distsp)[[1]])) #adding sequence as before
distgb3<-distgb2 %>% mutate(seq=seq(1:dim(distgb)[[1]]))

total_dist<-cbind(distsp3[colnam]+distgb3[match(distsp3$seq,distgb3$seq),colnam]) #matching the two and adding them to each

pbsz<-matrix(nrow=dim(total_dist)[[1]],ncol=dim(total_dist)[[2]]) #creating matriz to hold 

for(i in 1:5){ #calculating the z pbs value
  pbsz[,i]<-(total_dist[,i]-distgb[,"SP"])/2
}
colnames(pbsz)<-colnames(total_dist)#naming

subw<-val[,4]>20 #filter

plot(pbsz[subw,"PB"],pch=20,cex=.2,ylim=c(-10,30))

zpbs<-cbind(lift,pbsz) #plugging in location values

ord<-mixedorder(zpbs$V1) #Data imported is ordered alphabetically (ex. chr1, chr10...); this reorders it to alphanumeric (chr1, chr2...)
zpbsn<-zpbs[ord,] #applying sorted order to our dataset

write.table(zpbsn,"~/analysis/data/dfst/zpbs_20kb",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t") #writing

```

##Looking at 1% outlier regions

```{r}
col<-c() #figuring outliers
for (i in 1:5){
  col[i]<-quantile(zpbs[,i+3],prob=.99,na.rm=TRUE)
}
names(col)<-names(total_dist)
#1% thresholds
print(col)

```

##Creating outlier regions of interest

```{bash}
cat ~/analysis/data/dfst/zpbs_20kb | grep -v NA | \
awk '$4>3.231165 || $5>2.609672  || $6>3.752385 || $7>3.139116 || $8>2.731015' | \
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
-c 4,4,5,5,6,6,7,7,8,8 \
-o max,count,max,count,max,count,max,count,max,count \
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/dfst/zregions_max_20kb.bed
```

##Now let's plot up some figures with the merged z statistics

```{r}
zpbs<-zpbsn %>% 
  filter(str_detect(V1,"chr")) #filtering only chromosome mapped regions

#using data from the outlier regions in order to select regions of interest that are shared, res unique or interm unique
pbs_out_temp<-read.table("~/analysis/data/dfst/zregions_max_20kb.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBmax","BBcount","VBmax","VBcount","PBmax","PBcount","SJmax","SJcount","BNPmax","BNPcount") #naming columns
colnames(pbs_out_temp)<-names

pbs_out<-pbs_out_temp %>% filter(str_detect(Scaf,"chr")) #filtering to only select chromosome mapped scaffolds

all<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5] # vector wiht T/F of shared outliers
res<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
interm<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]

write.table(zpbs[,1:3],"~/analysis/data/dfst/zpbs.bed",row.names = FALSE,col.names = FALSE,quote=FALSE, sep="\t") #saving background genomic regions in bed format
write.table(pbs_out[all,1:3],"~/analysis/data/dfst/pbs_regions_sharedall.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t") #saving shared regions to look at overlap with the 1kb regions
write.table(pbs_out[res,1:3],"~/analysis/data/dfst/pbs_regions_sharedres.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t")
write.table(pbs_out[interm,1:3],"~/analysis/data/dfst/pbs_regions_sharedinterm.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t")

#only run source() and biocLite() if you don't have them installed
# source("http://bioconductor.org/biocLite.R")
# biocLite()
library("rtracklayer")

bed1=import("~/analysis/data/dfst/zpbs.bed")

bedall=import("~/analysis/data/dfst/pbs_regions_sharedall.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-findOverlaps(bedall,bed1)
allhit<-subjectHits(hitsall)

bedres=import("~/analysis/data/dfst/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/analysis/data/dfst/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

zpbs<-cbind(zpbs,0,0,0)
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm")
colnames(zpbs)<-newn
zpbs[allhit,"all"]<-zpbs[allhit,"all"]+1
zpbs[reshit,"res"]<-zpbs[reshit,"res"]+1
zpbs[intermhit,"interm"]<-zpbs[intermhit,"interm"]+1

zpbs$Scaf<-factor(zpbs$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24")) #factors are sometimes not sorted together with it, so sorting them separately

palette(c("grey40","grey80"))
par(mfrow=c(5,1),mar=c(0,3,0,0))
plot(zpbs[,4],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,5],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,6],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,7],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,8],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

```

## Decisions

* I think we ahve decided at this point to thoroughly go with PBS statistics for the paper, so I will use outliers from the PBS statistic to look at haplotype comparisons.

### Let's start by creating and plotting pbs outliers


```{r}

library(XML)
library(tidyr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(RCurl)
library(ggplot2)
library(reshape2)

load("~/analysis/data/comparison/noah_stats.RData") #loading data produced from individual SNP call pi and dxy calculations
pbstat2<-cbind(lift[,1:3],pbstat[,4:6],pbstat[,8],pbstat[,7]) #Binding pbs statistics for populations of interest, in this case F. grandis 

#Only run if you haven't created an ordered table of chromosomes
#r=ordering them by chromosome
# ord<-mixedorder(pbstat2$V1) #Data imported is ordered alphabetically (ex. chr1, chr10...); this reorders it to alphanumeric (chr1, chr2...)
# pbsn<-pbstat2[ord,] #applying sorted order to our dataset
# 
# pbsn$V1<-factor(pbsn$V1,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
#                                      "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
#                                      "chr20","chr21","chr22","chr23","chr24")) #factors are sometimes not sorted together with it, so sorting them separately
# 
# #writing table to be used in further analysis
# write.table(pbsn[,1:8],"~/analysis/data/fst/hudsonpbs_1kb.bed",row.names = FALSE,col.names = FALSE,quote=FALSE,sep='\t') #Not really necessary, but subsetting the data, so that you don't have to reorder every time

#reading in pbs table to find outlier regions
pbs<-read.table("~/analysis/data/fst/hudsonpbs_1kb.bed",header=FALSE) #loading in ordered table of pbs values for populations of interest
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs") #naming them according to their belonging
colnames(pbs)<-pbsname #applying naming scheme

quantiles<-c() #calculating quantiles in order to apply outlier thresholds
for(i in 1:5){
  quantiles[i]<-quantile(pbs[,i+3],probs=.99,na.rm=TRUE)
}


# Quantile info
# BBpbs - 0.18202835
# VBpbs - 0.14889788 
# PBpbs - 0.22912063 
# SJpbs - 0.08587848
# BNP - 0.04271162


```

## Using bedtools to merge outliers of these pbs statistics; removing non-mapped regions (noise for the most part)

```{bash}
#grabbing the table file (remember that it needs to be in bed format);
cat ~/analysis/data/fst/hudsonpbs_1kb.bed | \
#removing all NA
grep -v NA | \
#using awk to remove all values below outlier
awk '$4>0.18202835 || $5>0.14889788  || $6>0.22912063 || $7>0.08587848 || $8>0.04271162' | \
#piping into bedtools and merging into outlier windows within 50000 of each other
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
#which columns do you want summary statistics printed for
-c 4,4,5,5,6,6,7,7,8,8 \
#what statistics do you want printed
-o sum,count,sum,count,sum,count,sum,count,sum,count \
#using fai file to map those regions back to genomic regions and saving as bed file
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/fst/hudson_pbsmergeoutliers.bed

#doing the same but instead with summed statistic, with highest peak outliers
cat ~/analysis/data/fst/hudsonpbs_1kb.bed | \
grep -v NA | \
awk '$4>0.18202835 || $5>0.14889788  || $6>0.22912063 || $7>0.08587848 || $8>0.04271162' | \
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
-c 4,4,5,5,6,6,7,7,8,8 \
-o max,count,max,count,max,count,max,count,max,count \
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/fst/hudson_pbsmergeoutliers_max.bed

```

## Now taking these merged windows and plotting them to find common outliers

```{r}
PBSout<-read.table("~/analysis/data/fst/hudson_pbsmergeoutliers.bed",stringsAsFactors=FALSE) # Reading in the maximum outlier regions of interest
colnames(PBSout)<- c("Scaf","start","end","BBsum", "BBcount","VBsum","VBcount","PBsum","PBcount","SJsum","SJcount","BNPsum","BNPcount") #assigning them column names (we chose columns to be printed earlier)

BBtot<-sum(PBSout[,4]) #summing total level of divergence in these regions
VBtot<-sum(PBSout[,6])
PBtot<-sum(PBSout[,8])
SJtot<-sum(PBSout[,10])
BNPtot<-sum(PBSout[,12])

interest2<-c() #creating a vector of interest to weigh in the level of divergence by population, so that ones in most divergent populations don't get outweighed
for (i in 1:2119){
  interest2<-(PBSout[,4]/BBtot)*100+(PBSout[,6]/VBtot)*100+(PBSout[,8]/PBtot)*100+(PBSout[,10]/SJtot)*100+(PBSout[,12]/BNPtot)*100
}

ord<-order(interest2,decreasing=TRUE) #order that vector
ord2<-ord[1:10] #show top10 regions

par(mar=c(4.2,5,4,4)) #plotting these outliers
plot(PBSout[ord2,"BBsum"],col='black',pch=20,cex=3,ylim=c(0,4000),ylab="Level of divergence",xlab="Region number",
     cex.lab=2,cex.axis=2)
points(PBSout[ord2,"VBsum"],col='grey',pch=20,cex=3)
points(PBSout[ord2,"PBsum"],col='red',pch=20,cex=3)
points(PBSout[ord2,"SJsum"],col='darkorange',pch=20,cex=3)
points(PBSout[ord2,"BNPsum"],col="gold",pch=20,cex=3)

legend('topright',legend=c("BB","VB","PB","SJ","BNP"),col=c("black","grey","red","darkorange2","gold"),
       pch=20,cex=2,bty="n",y.intersp=1,x.intersp=.5)

```

## Grabbing those regions and putting them on pbs plots

```{r}
pbs<-read.table("~/analysis/data/fst/hudsonpbs_1kb.bed",header=FALSE,stringsAsFactors = FALSE) #reading in the windowed pbs estimates
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs") #naming columns
colnames(pbs)<-pbsname

col<-c()# finding 1% outliers
for (i in 1:5){
  col[i]<-quantile(pbs[,i+3],prob=.99,na.rm=TRUE)
}

pbsc<-pbs %>% filter(str_detect(Scaf,"chr")) #only selecting chromosomes

#removing the crappy scaffold that has the first 141 windows of chromosome 16 (mismapped from chr1); this is discovered in dxy.r script in introgression folder
chr16<-str_detect(pbsc$Scaf,"chr16") #grab chr16
ord<-order(pbsc[chr16,"BBpbs"],decreasing=TRUE) #pick highest value of chr16
pbsc16<-pbsc[chr16,] #make an object
chr16rows<-as.numeric(rownames(pbsc[chr16,])) #grab rownames for it
crappyrows<-chr16rows[1:300] #get the first 141 rows which contain scaffold "crappy"
pbsct<-pbsc[-c(crappyrows),] #remove thos rows from total
chr16.2<-str_detect(pbsc$Scaf,"chr16") #do it again
head(pbsct[chr16,])
pbsc<-pbsct
head(pbsc[chr16,])

#Grabbing regions that are put together pretty well/widely----
pbs_out_temp<-read.table("~/analysis/data/fst/hudson_pbsmergeoutliers_max.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBmax","BBcount","VBmax","VBcount","PBmax","PBcount","SJmax","SJcount","BNPmax","BNPcount")
colnames(pbs_out_temp)<-names

pbs_out<-pbs_out_temp %>% filter(str_detect(Scaf,"chr")) #selecting only chromosome mapped scaffolds

#checking for whether those are outliers in different groups--------
all<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]
res<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
interm<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]
bbu<-pbs_out[,4]>col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
vbu<-pbs_out[,4]<col[1] & pbs_out[,6]>col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
pbu<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
sju<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]<col[5]
bnpu<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]>col[5]

write.table(pbsc[,1:3],"~/analysis/data/fst/PBS_keep_1kb.bed",
            row.names = FALSE,col.names = FALSE,quote=FALSE,sep="\t")
write.table(pbs_out[all,1:3],"~/analysis/data/fst/pbs_regions_sharedall.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[res,1:3],"~/analysis/data/fst/pbs_regions_sharedres.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[interm,1:3],"~/analysis/data/fst/pbs_regions_sharedinterm.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[bbu,1:3],"~/analysis/data/fst/pbs_regions_sharedbbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[vbu,1:3],"~/analysis/data/fst/pbs_regions_sharedvbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[pbu,1:3],"~/analysis/data/fst/pbs_regions_sharedpbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[sju,1:3],"~/analysis/data/fst/pbs_regions_sharedsju.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[bnpu,1:3],"~/analysis/data/fst/pbs_regions_sharedbnpu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")


#source("http://bioconductor.org/biocLite.R")
#biocLite()
#biocLite('rtracklayer')

#Finding the overlaps in full data---------
library("rtracklayer")

bed1=import("~/analysis/data/fst/PBS_keep_1kb.bed") #importing the windows in which we are searching

bedall=import("~/analysis/data/fst/pbs_regions_sharedall.bed") #importing shared outliers
bed1overlall=bed1[bed1 %over% bedall] #Making overlapping regions into genome file
hitsall<-findOverlaps(bedall,bed1) #finding overlaps as hits
allhit<-subjectHits(hitsall) #making them into a true false vector

#same for the rest of the comparisons
bedres=import("~/analysis/data/fst/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/analysis/data/fst/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

bedbbu=import("~/analysis/data/fst/pbs_regions_sharedbbu.bed")
bed1overlbbu=bed1[bed1 %over% bedbbu]
hitsbbu<-findOverlaps(bedbbu,bed1)
bbuhit<-subjectHits(hitsbbu)

bedvbu=import("~/analysis/data/fst/pbs_regions_sharedvbu.bed")
bed1overlvbu=bed1[bed1 %over% bedvbu]
hitsvbu<-findOverlaps(bedvbu,bed1)
vbuhit<-subjectHits(hitsvbu)

bedpbu=import("~/analysis/data/fst/pbs_regions_sharedpbu.bed")
bed1overlpbu=bed1[bed1 %over% bedpbu]
hitspbu<-findOverlaps(bedpbu,bed1)
pbuhit<-subjectHits(hitspbu)

bedsju=import("~/analysis/data/fst/pbs_regions_sharedsju.bed")
bed1overlsju=bed1[bed1 %over% bedsju]
hitssju<-findOverlaps(bedsju,bed1)
sjuhit<-subjectHits(hitssju)

bedbnpu=import("~/analysis/data/fst/pbs_regions_sharedbnpu.bed")
bed1overlbnpu=bed1[bed1 %over% bedbnpu]
hitsbnpu<-findOverlaps(bedbnpu,bed1)
bnpuhit<-subjectHits(hitsbnpu)

pbsc<-cbind(pbsc,0,0,0,0,0,0,0,0) #adding columns to the dataframe of pbs values
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm","bbu","vbu","pbu","sju","bnpu") #giving them names
colnames(pbsc)<-newn
pbsc[allhit,"all"]<-pbsc[allhit,"all"]+1 #adding 1s for true values in hits parameter
pbsc[reshit,"res"]<-pbsc[reshit,"res"]+1
pbsc[intermhit,"interm"]<-pbsc[intermhit,"interm"]+1
pbsc[bbuhit,"bbu"]<-pbsc[bbuhit,"bbu"]+1
pbsc[vbuhit,"vbu"]<-pbsc[vbuhit,"vbu"]+1
pbsc[pbuhit,"pbu"]<-pbsc[pbuhit,"pbu"]+1
pbsc[sjuhit,"sju"]<-pbsc[sjuhit,"sju"]+1
pbsc[bnpuhit,"bnpu"]<-pbsc[bnpuhit,"bnpu"]+1

#plotting those results by using the pbs_out vector; too messy, let's just plot with shared type outliers-------------
# pbsc$Scaf<-factor(pbsc$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
#                                      "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
#                                      "chr20","chr21","chr22","chr23","chr24")) #ordering factor levels
# palette(c("grey40","grey80"))
# par(mfrow=c(5,1),mar=c(0,3,0,0))
# plot(pbsc[,4],pch=20,cex=1.2,
#      col=ifelse(pbsc[,"all"]>0,"purple",
#                 ifelse(pbsc[,"res"]>0,"black",
#                        ifelse(pbsc[,"interm"]>0,"firebrick2",
#                               ifelse(pbsc[,"bbu"]>0,"gold2",
#                                      ifelse(pbsc[,4]>col[1],"green2",as.factor(pbsc[,1])))))),
#      xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")
# 
# plot(pbsc[,5],pch=20,cex=1.2,
#      col=ifelse(pbsc[,"all"]>0,"purple",
#                 ifelse(pbsc[,"res"]>0,"black",
#                        ifelse(pbsc[,"interm"]>0,"firebrick2",
#                               ifelse(pbsc[,"vbu"]>0,"gold2",
#                                      ifelse(pbsc[,5]>col[2],"green2",as.factor(pbsc[,1])))))),
#      xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")
# 
# plot(pbsc[,6],pch=20,cex=1.2,
#      col=ifelse(pbsc[,"all"]>0,"purple",
#                 ifelse(pbsc[,"res"]>0,"black",
#                        ifelse(pbsc[,"interm"]>0,"firebrick2",
#                               ifelse(pbsc[,"pbu"]>0,"gold2",
#                                      ifelse(pbsc[,6]>col[3],"green2",as.factor(pbsc[,1])))))),
#      xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")
# 
# plot(pbsc[,7],pch=20,cex=1.2,
#      col=ifelse(pbsc[,"all"]>0,"purple",
#                 ifelse(pbsc[,"res"]>0,"black",
#                        ifelse(pbsc[,"interm"]>0,"firebrick2",
#                               ifelse(pbsc[,"sju"]>0,"gold2",
#                                      ifelse(pbsc[,7]>col[4],"green2",as.factor(pbsc[,1])))))),
#      xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")
# 
# plot(pbsc[,8],pch=20,cex=1.2,
#      col=ifelse(pbsc[,"all"]>0,"purple",
#                 ifelse(pbsc[,"res"]>0,"black",
#                        ifelse(pbsc[,"interm"]>0,"firebrick2",
#                               ifelse(pbsc[,"bnpu"]>0,"gold2",
#                                      ifelse(pbsc[,8]>col[5],"green2",as.factor(pbsc[,1])))))),
#      xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")

#Simplified to fewer outliers----

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/pbs.jpg",width=1000,height=1200)
pbsc$Scaf<-factor(pbsc$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))
palette(c("grey40","gold"))
par(mfrow=c(5,1),mar=c(0,3,0,0))
plot(pbsc[,4],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,5],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                            as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,6],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,7],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,8],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-.5,3.8),yaxs="i")
dev.off()

```

## Breaking these up into 1kb windows and observing whether they are unique

```{r}
###Plotting outliers vs each other-----------
pbsct<-pbs %>% filter(str_detect(Scaf,"chr")) #getting only scaffolds mapped onto chromosomes here

pbsc<-na.omit(pbsc[,1:8]) #removing NA values from them

#checking for whether those are outliers in different groups
all<-pbsc[,4]>col[1] & pbsc[,5]>col[2] & pbsc[,6]>col[3] & pbsc[,7]>col[4] & pbsc[,8]>col[5]
res<-pbsc[,4]>col[1] & pbsc[,5]>col[2] & pbsc[,6]>col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
interm<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]>col[4] & pbsc[,8]>col[5]
bbu<-pbsc[,4]>col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
vbu<-pbsc[,4]<col[1] & pbsc[,5]>col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
pbu<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]>col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
sju<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]>col[4] & pbsc[,8]<col[5]
bnpu<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]>col[5]

#as before, checking which of those regions of divergence maps to specific windows of divergence
write.table(pbsc[,1:3],"~/analysis/data/fst/subsample/PBS_keep_1kb.bed",row.names = FALSE,col.names = FALSE,quote=FALSE,sep='\t')
write.table(na.omit(pbsc[all,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedall.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[res,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedres.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[interm,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedinterm.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[bbu,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedbbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[vbu,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedvbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[pbu,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedpbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[sju,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedsju.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[bnpu,1:3]),"~/analysis/data/fst/subsample/pbs_regions_sharedbnpu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')


#source("http://bioconductor.org/biocLite.R")
#biocLite()
#biocLite('rtracklayer')

#Finding the overlaps in full data---------
library("rtracklayer")

#summarizing these outlier windows, instead of by regions, by 1kb windows - look behind if confused about script (previous chunk)
bed1=import("~/analysis/data/fst/subsample/PBS_keep_1kb.bed")

bedall=import("~/analysis/data/fst/subsample/pbs_regions_sharedall.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-findOverlaps(bedall,bed1)
allhit<-subjectHits(hitsall)

bedres=import("~/analysis/data/fst/subsample/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/analysis/data/fst/subsample/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

bedbbu=import("~/analysis/data/fst/subsample/pbs_regions_sharedbbu.bed")
bed1overlbbu=bed1[bed1 %over% bedbbu]
hitsbbu<-findOverlaps(bedbbu,bed1)
bbuhit<-subjectHits(hitsbbu)

bedvbu=import("~/analysis/data/fst/subsample/pbs_regions_sharedvbu.bed")
bed1overlvbu=bed1[bed1 %over% bedvbu]
hitsvbu<-findOverlaps(bedvbu,bed1)
vbuhit<-subjectHits(hitsvbu)

bedpbu=import("~/analysis/data/fst/subsample/pbs_regions_sharedpbu.bed")
bed1overlpbu=bed1[bed1 %over% bedpbu]
hitspbu<-findOverlaps(bedpbu,bed1)
pbuhit<-subjectHits(hitspbu)

bedsju=import("~/analysis/data/fst/subsample/pbs_regions_sharedsju.bed")
bed1overlsju=bed1[bed1 %over% bedsju]
hitssju<-findOverlaps(bedsju,bed1)
sjuhit<-subjectHits(hitssju)

bedbnpu=import("~/analysis/data/fst/subsample/pbs_regions_sharedbnpu.bed")
bed1overlbnpu=bed1[bed1 %over% bedbnpu]
hitsbnpu<-findOverlaps(bedbnpu,bed1)
bnpuhit<-subjectHits(hitsbnpu)

pbsc<-cbind(pbsc,0,0,0,0,0,0,0,0) #adding these to the 1kb windows we've separated the genome into
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm","bbu","vbu","pbu","sju","bnpu")
colnames(pbsc)<-newn
pbsc[allhit,"all"]<-pbsc[allhit,"all"]+1 #naming adding +1 to each of those windows that is shared
pbsc[reshit,"res"]<-pbsc[reshit,"res"]+1
pbsc[intermhit,"interm"]<-pbsc[intermhit,"interm"]+1
pbsc[bbuhit,"bbu"]<-pbsc[bbuhit,"bbu"]+1
pbsc[vbuhit,"vbu"]<-pbsc[vbuhit,"vbu"]+1
pbsc[pbuhit,"pbu"]<-pbsc[pbuhit,"pbu"]+1
pbsc[sjuhit,"sju"]<-pbsc[sjuhit,"sju"]+1
pbsc[bnpuhit,"bnpu"]<-pbsc[bnpuhit,"bnpu"]+1

par(mfrow=c(2,3),mar=c(4,4,0,0)) #plotting these outlier windows vs each other for each population to see how they are distributed among resistant and intermediate populations
plot(pbsc[,"BB"],pbsc[,"VB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="VB z values",ylab="BB z values")
abline(h=0,v=0)

plot(pbsc[,"BB"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="BB z values")
abline(h=0,v=0)

plot(pbsc[,"VB"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="VB z values")
abline(h=0,v=0)

plot(pbsc[,"SJ"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="SJ z values")
abline(h=0,v=0)

plot(pbsc[,"BNP"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="BNP z values")
abline(h=0,v=0)

plot(pbsc[,"BNP"],pbsc[,"SJ"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="SJ z values",ylab="BNP z values")
abline(h=0,v=0)
```

## Test for finding if they are truly different by simulating 1000 random regions of the same size from the genome

```{r}

intermeans<-c()
for(i in 1:5){
  intermeans[i]<-mean(pbsc[interm,i+3],na.rm=TRUE)
}

resmeans<-c()
for(i in 1:5){
  resmeans[i]<-mean(pbsc[res,i+3],na.rm=TRUE)
}

allmeans<-c()
for(i in 1:5){
  allmeans[i]<-mean(pbsc[all,i+3],na.rm=TRUE)
}

#plotting histogram for intermediate regions----
rimeans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=765,replace=FALSE))
  }
  rimeans<-cbind(rimeans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rimeans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

par(mfrow=c(2,3),mar=c(4,4,2,2))
for(i in 1:length(nam)){
  hist(rimeans[,i],main='',breaks=30,xlim=c(range(rimeans[,i]-.1,na.rm=TRUE)[[1]],intermeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i],cex.axis=3,ylab='')
  abline(v=intermeans[i],lwd=3,col="green")
  box(bty='l',lwd=3)
}

#plotting histogram for resistant only regions----

rrmeans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=2549,replace=FALSE))
  }
  rrmeans<-cbind(rrmeans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rrmeans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

par(mfrow=c(2,3))
for(i in 1:length(nam)){
  hist(rrmeans[,i],main='',breaks=30,xlim=c(range(rrmeans[,i]-.1,na.rm=TRUE)[[1]],resmeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i])
  abline(v=resmeans[i],lwd=3,col="green")
}

###plotting histogram for shared regions----

rameans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=259,replace=FALSE))
  }
  rameans<-cbind(rameans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rameans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

par(mfrow=c(2,3))
for(i in 1:length(nam)){
  hist(rameans[,i],main='',breaks=30,xlim=c(range(rameans[,i]-.1,na.rm=TRUE)[[1]],allmeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i])
  abline(v=allmeans[i],lwd=3,col="green")
}

```


## Plotting specific regions of the genome based on divergence - messed up for now, will have to re-do

```{r}
#smoothing funciton----
subsmooth <- function(vec,by=10,width=11){
  
  len <- length(vec)
  subl <- seq(from=by,to=len,by=by)
  submax <- length(subl)
  width <- width/2
  test <- vec[subl]
  
  for(i in 1:submax){
    
    j <- i - width
    k <- i + width
    if(j < 1) {j <- 1}
    if(k > submax) {k <- submax}
    test[i] <- mean(test[j:k],na.rm=TRUE)
  }
  
  return(test)
  
}


###Plotting CHR1/AHR region------------
pbsc1<-pbsc %>% filter(str_detect(Scaf,"\\bchr1\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc1[1:5000,i+3]),pch=20,cex=.5,ylim=c(0,1.8),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(50,60),col="red",lty=2,lwd=1.5)
}

#plotting ARNT chr8----
pbsc8<-pbsc %>% filter(str_detect(Scaf,"\\bchr8\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc8[14000:18000,i+3]),pch=20,cex=.5,ylim=c(0,.5),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(170,173),col="red",lty=2,lwd=1.5)
}


#plotting AIP chr2----
pbsc2<-pbsc %>% filter(str_detect(Scaf,"\\bchr2\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc2[23000:26000,i+3]),pch=20,cex=.5,ylim=c(0,.4),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(140,142),col="red",lty=2,lwd=1.5)
}

#plotting AQP3

pbsc24<-pbsc %>% filter(str_detect(Scaf,"\\bchr24\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc24[22000:26000,i+3]),pch=20,cex=.5,ylim=c(0,.5),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(159,162),col="red",lty=2,lwd=1.5)
}

#plotting AQP3

pbsc11<-pbsc %>% filter(str_detect(Scaf,"\\bchr11\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc11[27000:28940,i+3]),pch=20,cex=.5,ylim=c(0,.5),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(181,188),col="red",lty=2,lwd=1.5)
}

```    

##Looking at MDS of haplotypes

* removing regions of introgression from considered regions (Chr 1 and 10) and converting to tabix readable format

```{bash}
cat ~/analysis/data/fst/pbs_regions_sharedall.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/analysis/data/fst/hudson_out_all.txt

#will use the one with introgressed regions for expectations
cat ~/analysis/data/fst/pbs_regions_sharedall.bed | \
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/analysis/data/fst/hudson_out_all_intr.txt

cat ~/analysis/data/fst/pbs_regions_sharedres.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/analysis/data/fst/hudson_out_res.txt

cat ~/analysis/data/fst/pbs_regions_sharedinterm.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/analysis/data/fst/hudson_out_interm.txt

```

* Then I grab all those regions from the vcf file in order to haploidize the genotype likelihoods

```{bash}
#shared sites

#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_all.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_all.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#shared with introgressed
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_all_intr.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_all_intr.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#resistant only
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_res.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_res.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#intermediate only
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_interm.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_interm.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#downloading to personal computer

scp kodiak:/data/oziolore/fhet/data/outliers/hudson*.vcf.bgz /home/elias/analysis/data/fst/

```

* I used a script (based on Noah Reid's script) that haploidizes genotypes based of low coverage data and just pass each file through them. Script below is called haploidize_gran_mine.r

```{r}
#!/usr/bin/env Rscript

library(stringr)
library(magrittr)

sam<-function(x){
      y <- str_split(x,":")[[1]][1] %>% 
    			 str_split(.,"\\/") %>% 
    			 unlist() %>% 
    			 as.numeric() # pull genotypes
      if(is.na(y)){
        return(".")
      } else {
          z<-str_split(x,":")[[1]][3] %>% 
             str_split(.,",") %>% 
             unlist() %>% 
             as.numeric() # pull allele coverage
          if(y[1]==y[2]){
            h<-y[1]
          } else {
            if(z[1]>z[2]){
              h<-y[1]
            } else {
              h<-sample(y,size=1)
            }
          }
        return(h)
      }
}

f <- file("stdin")
#f<-file("~/analysis/data/dfst/outliers/zshared.vcf.bgz")
open(f)
while(length(line <- readLines(f,n=1)) > 0) {
  if(grepl("^#",line)){write(line,stdout());next()}

  line <- str_split(line,"\\t") %>% unlist()
  line[10:297] <- sapply(line[10:297],sam)
  line <- paste(line,collapse="\t")
  write(line,stdout())
  # write(line, stderr())
  # process line
}
```

* using bash to haploidize each vcf file

```{bash}
zcat ~/analysis/data/fst/hudson_out_all.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/hudson_out_all_haplo.vcf.bgz

zcat ~/analysis/data/fst/hudson_out_res.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/hudson_out_res_haplo.vcf.bgz

zcat ~/analysis/data/fst/hudson_out_interm.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/hudson_out_interm_haplo.vcf.bgz
```

* plotting haplotypes
  + starting with resistant only haplotypes (because they finished first)
```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/hudson_out_res_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(dd)
tr <- nj(dd)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)

legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),
       pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

* repeating with shared haplotypes

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/hudson_out_all_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
#do not need to impute here because there are no missing values
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/pbs_sharedout.jpg",width=1000,height=400)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()
#legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

* finally intermediate haplotypes

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/hudson_out_interm_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
#do not need to impute here because there are no missing values
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/pbs_intermout.jpg",width=1000,height=400)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()

#legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

## Running admixture on the data

```{bash}
#starting by converting vcf to bed file through plink
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=02:00:00

#programs and files
my_plink=/data/oziolore/program/plink/plink
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_tabix=/data/oziolore/program/htslib/tabix
my_out=/data/oziolore/fhet/data/admixture/allscaf/allscaf

$my_plink \
-vcf $my_vcf \
--allow-extra-chr \
--make-bed \
-out $my_out

#continue by removing NW from file because it messes up with total number of chromosomes allowed
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#files
start_bim=/data/oziolore/fhet/data/admixture/allscaf/allscaf.bim
end_bim=/data/oziolore/fhet/data/admixture/allscaf/allscaf2.bim

cat $start_bim | awk '{gsub("NW_","");print}' > $end_bim

#running admixture for k 1-7 because we sampled 7 total populations
#!/bin/bash

#PBS -l nodes=1:ppn=16
#PBS -J 1-7
#PBS -l walltime=48:00:00

#programs
admix=/data/oziolore/program/admixture/admixture
allscaf=/data/oziolore/fhet/data/admixture/allscaf/allscaf.bed
out=/data/oziolore/fhet/data/admixture/allscaf

$admix --cv -j16 $allscaf $PBS_ARRAY_INDEX | tee $out/log${PBS_ARRAY_INDEX}.out

```

###Plotting admixture proportions

```{r}
ord_temp<-read.table("~/analysis/data/admixture/seqlist.txt",header=FALSE)
ord<-unlist(ord_temp)

k2<-read.table("~/analysis/data/admixture/all/allscaf.2.Q")
k2ord<-k2[ord,]
barplot(t(as.matrix(k2ord)),col=c("deepskyblue2","black"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis=1.5)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)
abline(a=0,b=0,col="black",lwd=3)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("SP","GB","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

gb<-k2ord[0:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k2ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k2ord[97:144,]
bnpord<-order(bnp[,2],decreasing=TRUE)

sj<-k2ord[145:168,]
sjord<-order(sj[,2],decreasing=TRUE)

pb<-k2ord[168:215,]
pbord<-order(pb[,2],decreasing=TRUE)

vb<-k2ord[215:264,]
vbord<-order(vb[,2],decreasing=TRUE)

bb<-k2ord[265:288,]
bbord<-order(bb[,2],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],gb[gbord,],sp[spord,])

kall<-na.omit(kall)

par(mfrow=c(1,1),mar=c(3,3,1,1))
barplot(t(as.matrix(kall)),col=c("cadetblue2","black"), border=NA, xaxt="n",space=0,
        cex.lab=2,cex.axis=1.9)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,121,122,193,194,288)
vert<-c(24,74,122,146,194,242)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)

########################################################
k3<-read.table("~/analysis/data/admixture/all/allscaf.3.Q")
k3ord<-k3[ord,]
barplot(t(as.matrix(k3ord)),col=c("black","deepskyblue2","red"), ylab="Ancestry",border=NA, xaxt="n",space=0)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("SP","GB","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

##########################################################
k4<-read.table("~/analysis/data/admixture/all/allscaf.4.Q")
k4ord<-k4[ord,]

gb<-k4ord[0:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k4ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k4ord[97:144,]
bnpord<-order(bnp[,3],decreasing=TRUE)

sj<-k4ord[145:168,]
sjord<-order(sj[,3],decreasing=TRUE)

pb<-k4ord[168:215,]
pbord<-order(pb[,3],decreasing=TRUE)

vb<-k4ord[215:264,]
vbord<-order(vb[,3],decreasing=TRUE)

bb<-k4ord[265:288,]
bbord<-order(bb[,3],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],gb[gbord,],sp[spord,])

kall<-na.omit(kall)
barplot(t(as.matrix(kall)),col=c("red","deepskyblue2","black","darkorange"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis = 1.5)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,121,122,193,194,288)
vert<-c(24,74,122,146,194,242)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)
```

##Decided to run NGS admix to figure out proportion that came from BB and GB (most fst divergent populations)

```{bash}
#start by creating a reference panel for ngs admix (two most highly divergent fst pops)
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=00:30:00

#programs and files
my_plink=/data/oziolore/program/plink/plink
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_tabix=/data/oziolore/program/htslib/tabix
my_out=/data/oziolore/fhet/data/fastngs/reference_panel_all
my_keep=/data/oziolore/fhet/data/list2/fastngs_reference_all.txt

$my_plink \
-vcf $my_vcf \
--allow-extra-chr \
--keep $my_keep \
--make-bed \
--chr 1-24 \
-out $my_out

#run admixture on the reference panel of 2 populations

#!/bin/bash

#PBS -l nodes=1:ppn=16
#PBS -l walltime=05:00:00

my_admix=/data/oziolore/program/admixture/admixture
my_ref=/data/oziolore/fhet/data/fastngs/reference_panel.bed
my_out=/data/oziolore/fhet/data/fastngs

$my_admix --cv -j16 $my_ref 2 | tee $my_out/log2

#create the panel by re-modeling the output of admixture

echo "id chr pos name A0_freq A1 K1 K2" > refPanel_BBGB.2.P.txt
 paste -d" " <( awk -F " " ' { print $1"_"$4, $1, $4, $2, $6, $5 } ' /data/oziolore/fhet/data/fastngs/reference_panel.bim ) reference_panel.2.P >> refPanel_BBGB.2.P.txt
 echo "K1 K2" > nInd_BBGB.2.Q.txt
 paste -d" " <(cut -f1 -d" " /data/oziolore/fhet/data/fastngs/reference_panel.2.Q | paste -sd+ | bc) <(cut -f2 -d" " /data/oziolore/fhet/data/fastngs/reference_panel.2.Q | paste -sd+ | bc) >> nInd_BBGB.2.Q.txt

#create a beagle file for ngsadmix to use

#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -l walltime=24:00:00
#PBS -J 1-288

list=/data/oziolore/fhet/data/list2/pop_files.txt
f=$(echo $PBS_ARRAY_INDEX)
ind=$(cat $list | sed "${f}q;d")
name=$(cat $list | sed "${f}q;d" | grep -o "BU.*")
sites=/data/oziolore/fhet/data/fastngs/refPanel_BBGB.sites
my_angsd=/data/oziolore/program/angsd/angsd
my_out=/data/oziolore/fhet/data/fastngs/beagle_big/$name\

$my_angsd \
-i $ind \
-GL 2 \
-sites $sites \
-doGlf 2 \
-doMajorMinor 3 \
-minMapQ 30 \
-minQ 20 \
-doDepth 1 \
-doCounts 1 \
-out $my_out

#Run fastngsadmix with the reference panel on the populations you want to know the proportions of admixture
#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -l walltime=24:00:00
#PBS -J 1-288

list=/data/oziolore/fhet/data/list2/pop_files.txt
f=$(echo $PBS_ARRAY_INDEX)
name=$(cat $list | sed "${f}q;d" | grep -o "BU.*")
my_fastngs=/data/oziolore/program/fastNGSadmix/fastNGSadmix
my_GL=/data/oziolore/fhet/data/fastngs/beagle_big/$name\.beagle\.gz
my_out=/data/oziolore/fhet/data/fastngs/probs_big/$name
ref=/data/oziolore/fhet/data/fastngs/refPanel_BBGB_big_new.2.P.txt
numb=/data/oziolore/fhet/data/fastngs/nInd_BBGB_big.2.Q.txt

$my_fastngs \
-likes $my_GL \
-fname $ref \
-Nname $numb \
-whichPops all \
-seed 1 \
-boot 100 \
-out $my_out

#combine probabilities from all files
for i in {004..464}; do cat BU000$i*.qopt | head -n2 | grep -v "K1" >> combined_probs.txt

```

* take this out into r and plot the probabilities

```{r}
ord_temp<-read.table("~/analysis/data/fastngs/order.txt",header=FALSE)
ord<-unlist(ord_temp)

k2<-read.table("~/analysis/data/fastngs/combined_probs.txt")
k2ord<-k2[ord,]
barplot(t(as.matrix(k2ord)),col=c("deepskyblue2","black"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis=1.5)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)
abline(a=0,b=0,col="black",lwd=3)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("GB","SP","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

gb<-k2ord[1:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k2ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k2ord[97:144,]
bnpord<-order(bnp[,2],decreasing=TRUE)

sj<-k2ord[145:168,]
sjord<-order(sj[,2],decreasing=TRUE)

pb<-k2ord[169:215,]
pbord<-order(pb[,2],decreasing=TRUE)

vb<-k2ord[216:264,]
vbord<-order(vb[,2],decreasing=TRUE)

bb<-k2ord[265:288,]
bbord<-order(bb[,2],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],sp[spord,],gb[gbord,])

kall<-na.omit(kall)

par(mfrow=c(1,1),mar=c(3,3,1,1))
barplot(t(as.matrix(kall)),col=c("cadetblue2","black"), border=NA, xaxt="n",space=0,
        cex.lab=2,cex.axis=1.9)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,120,121,192,193,288)
vert<-c(24,73,120,143,191,239)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)

###histograms and densities

gbh<-density(gb[,1],na.rm=TRUE)
sph<-density(sp[,1],na.rm=TRUE)
bnph<-density(bnp[,1],na.rm=TRUE)
sjh<-density(sj[,1],na.rm=TRUE)
pbh<-density(pb[,1],na.rm=TRUE)
vbh<-density(vb[,1],na.rm=TRUE)
bbh<-density(bb[,1],na.rm=TRUE)

plot(bbh,col="black",ylim=c(0,48),xlim=c(-.2,1.2))
lines(vbh,col="grey50")
lines(pbh,col="red")
lines(sjh,col="darkorange")
lines(bnph,col="gold")
lines(sph,col="cyan")
lines(gbh,col="blue")

#separate

par(mfrow=c(2,1),mar=c(2,4,1,1))

plot(bbh,col="black",ylim=c(0,7),xlim=c(-.2,1.2),
     main="",xaxt='n',
     cex.axis=1.2,lwd=2,bty="l")
lines(vbh,col="black",lwd=2)
lines(pbh,col="black",lwd=2)

legend('topright',legend=c("resistant","intermediate","reference"),col=c("black","red","blue"),
       pch=20,cex=1.5,bty="n",y.intersp=1,x.intersp=.5)

plot(sjh,col="red",ylim=c(0,48),xlim=c(-.2,1.2),main="",
     cex.axis=1.2,lwd=2,bty="l")
lines(bnph,col="red",lwd=2)
lines(sph,col="blue",lwd=2)
lines(gbh,col="blue",lwd=2)
# 
# legend('topleft',legend=c("intermediate","reference"),col=c("red","blue"),
#        pch=20,cex=1.5,bty="n",y.intersp=1,x.intersp=.5)


###
#install.packages("diptest")
library(diptest)

dip.test(bb[,1],simulate.p.value = TRUE,B=2000)
#p=0.92
dip.test(vb[,1],simulate.p.value = TRUE,B=2000)
#p=0.22
dip.test(pb[,1],simulate.p.value = TRUE,B=2000)
#p=0.0015
dip.test(sj[,1],simulate.p.value = TRUE,B=2000)
#p=0.99
dip.test(bnp[,1],simulate.p.value = TRUE,B=2000)
#p=0.99
dip.test(sp[,1],simulate.p.value = TRUE,B=2000)
#p=1
dip.test(gb[,1],simulate.p.value = TRUE,B=2000)
#p=1

###Probs of admixture
a<-matrix(nrow =1,ncol=7)
a[,1]<-sum(bb[,2])/length(bb[,2])
a[,2]<-sum(vb[,2])/length(vb[,2])
a[,3]<-sum(pb[,2])/length(pb[,2])
a[,4]<-sum(sj[,2])/length(sj[,2])
a[,5]<-sum(bnp[,2])/length(bnp[,2])
a[,6]<-sum(sp[,2])/length(sp[,2])
a[,7]<-sum(gb[,2])/length(gb[,2])
colnames(a)<-c("bb","vb","pb","sj","bnp","sp","gb")
rownames(a)<-"alpha"

write.table(a,"~/analysis/data/fastngs/alpha",quote=FALSE,row.names=FALSE)

```

* this gave us an expectation for all allele frequencies for outlier regions.

* now let's see if those match what the frequencies actually are

```{r}
library(viridis)
library(dplyr)
library(magrittr)
library(stringr)
library(gtools)
library(rtracklayer)
library(ggplot2)
library(ggsci)

pbs_dist<-read.table("~/analysis/data/fst/hudsonpbs_1kb.bed",header=FALSE)
distnames<-c("Scaf","start","end","bb","vb","pb","sj","bnp")
colnames(pbs_dist)<-distnames
col<-c()
for (i in 1:5){
  col[i]<-quantile(pbs_dist[,i+3],prob=.99,na.rm=TRUE)
}


z<-read.table("~/analysis/data/expectations/hudson_pbsmergeoutliers_max.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBmax","BBcount","VBmax","VBcount","PBmax","PBcount","SJmax","SJcount","BNPmax","BNPcount")
colnames(z)<-names

all<-z[,4]>col[1] & z[,6]>col[2] & z[,8]>col[3] & z[,10]>col[4] & z[,12]>col[5]

###Reading in VCF for outlier regions that include introgression, formatting ----
vcf<-read.table("~/analysis/data/fst/hudson_out_all_intr_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
#vcf<-cbind(vcf[,1],vcf[,2]-1,vcf[,2:297]) #Converting the first three columns into bed type format
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

subw<-nchar(vcf[,5])<2 #using only biallelic SNPs

vcf<-vcf[subw,] #restricting to biallelic SNPs

table(nchar(vcf[,4])>2) #Confirming biallelic SNPs with reference allele after restriction

gt<-as.matrix(vcf[,10:297]) #convert to numeric
class(gt)<-"numeric"

keep<-colMeans(is.na(gt))<0.9 #toss sites with low coverage
gt<-gt[,keep]

#Summing SNP frequencies----

popfr<-cbind(vcf[,1:2])
nam<-c("chr","pos","BB","VB","PB","SJ","BNP","SP","GB")

for(j in 1:length(nam[-1:-2])){
  b<-gt[,grepl(nam[j+2],colnames(gt))]
  f<-as.numeric(rowSums(gt[,grepl(nam[j+2],colnames(gt))],na.rm=TRUE)/ncol(b))
  popfr<-cbind(popfr,f)
  print(nam[j+2])
  print(ncol(b))
}
#summed frequencies over all individuals 
colnames(popfr)<-nam

res<-(rowSums(popfr[,3:5])/3) #summing SNP frequencies over resistant sites and below for all other
int<-(rowSums(popfr[,6:7])/2)
ref<-(rowSums(popfr[,8:9])/2)
rr<-cbind(popfr[,1:2],res,ref,int) #merging these into a single DF

quantile(with(rr,res-ref),probs=0.97)
plot(rr[,"res"]-rr[,"ref"],pch=20,cex=.4,col=ifelse(res-ref>.13,"red","black")) #Plotting difference between res and ref
subw<-with(rr,res-ref)>.13

plot(rr[subw,"res"]-rr[subw,"int"],pch=20,cex=.4,col="firebrick2")
points(rr[subw,"res"]-rr[subw,"ref"],pch=20,cex=.4,col="cadetblue3")

#just plotting where intermediates would lie
# plot(with(rr,(res-int)/(res-ref)),pch=20,cex=.5)
# 
# ggplot(data=rr,
#        aes((res-int)/(res-ref)))+
#   geom_histogram()

###Frequency of haplotypes in individuals based on those SNPs----

vcfo<-vcf[subw,] #using only the biallelic SNPs that are in the 97th percentile of allele frequency difference
zn<-na.omit(z[all,1:3]) #using the rows of merged divergent regions to create regions from which I will merge SNPs
nam<-c("chr","start","end")
colnames(zn)<-nam

vcfo<-cbind(vcfo[,1],vcfo[,2]-1,vcfo[,2:297]) #making vcfo into a bed file
write.table(vcfo[,1:3],"~/analysis/data/expectations/vcf_hudpbs_out.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(zn[,1:3],"~/analysis/data/expectations/hudpbs_shared_all.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')

library(rtracklayer)

bed1=import("~/analysis/data/expectations/vcf_hudpbs_out.bed")
bedall=import("~/analysis/data/expectations/hudpbs_shared_all.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-countOverlaps(bedall,bed1) #crScienceeating a vector of overlap counts - # SNPs present in that overlap

gt<-as.matrix(vcfo[,10:297]) #convert to numeric
class(gt)<-"numeric"
keep<-colMeans(is.na(gt))<0.9 #toss sites with low coverage
gt<-gt[,keep]

fr<-c() #this is used to create a matrix of frequencies of the haplotype in each outlier window by counting the number of SNPs in it
j=0
for(i in 1:length(hitsall)){
  if(hitsall[i]>1){
  f<-as.numeric(colSums(gt[(j+1):(hitsall[i]+j),],na.rm=TRUE)/hitsall[i])
  fr<-rbind(fr,f)
  j=j+hitsall[i]
  print(j==sum(hitsall[1:i]))
  print(i)
  } else if (hitsall[i]==1){
    j=j+1
  }
}

colnames(fr)<-colnames(gt)

#Calling individuals as 0,0.5,1 frequency of haplotype ----
#I'll make a judgment call that anything below 0.1 is absence, anything above 0.6 is presence in full, anything in between is half
frr<-fr
for(i in 1:dim(fr)[[2]]){
  for(j in 1:dim(fr)[[1]]){
    if(fr[j,i]<0.1){
      frr[j,i]<-as.numeric(0)
    } else if (fr[j,i]>0.6){
      frr[j,i]<-as.numeric(1)
    } else{
      frr[j,i]<-as.numeric(0.5)
    }
  }
}

###Summing allele frequencies over populations----

nam<-c("BB","VB","PB","SJ","BNP","SP","GB")
subw<-hitsall>1

pfr<-zn[subw,1:3]
for(i in 1:length(nam)){
  f<-as.numeric(rowSums(frr[,grepl(nam[i],colnames(frr))],na.rm=TRUE))/ncol(frr[,grepl(nam[i],colnames(frr))])
  pfr<-cbind(pfr,f)
}

colnames(pfr)<-c(colnames(pfr[1:3]),nam)

pfr<-t(pfr[4:10])

# plot(pfr[,1],ylim=c(0,.5))
# for(i in 1:dim(pfr)[[2]]){
#   lines(pfr[,i],ylim=c(0,.5))
# }

#Seeing if those frequencies meet expectations from admixture----
a<-read.table("~/analysis/data/fastngs/alpha",header=TRUE)
a<-as.numeric(a)

e<-c() #creating a vector e of expected values for each allele
r<-c()
for(i in 1:dim(pfr)[[2]]){
  for(j in 1:dim(pfr)[[1]]){
    b<-a[j]*pfr[1,i]+(1-a[j])*pfr[7,i]
    r[j]<-b
  }
  e<-cbind(e,r)
}

rownames(e)<-rownames(pfr)
colnames(e)<-colnames(pfr)

efr<-pfr-e
colnames(efr)<-(zn[subw,1])
efr1<-efr[,grepl("chr",colnames(efr))]

par(mar=c(4,4,2,2))
plot(efr[,1],ylim=c(-.2,.4),type='n',xaxt='n',
     ylab="Deviation from expected allele frequencies due to admixture",bty='l')
for(i in 1:dim(efr)[[2]]){
  lines(efr[,i],ylim=c(0,.5),lwd=ifelse(zn[i,1]=="chr1",3,
                                        ifelse(zn[i,1]=="chr8",3,0.8))
        ,col=ifelse(zn[i,1]=="chr1","blue",
                    ifelse(zn[i,1]=="chr8","green","black")))
}
axis(side=1,at=1:7,labels=c(rownames(efr)))
abline(h=1,lwd=3,lty=2,col="black")

#Color by chromosome ----
chr<-unique(colnames(efr1))
# color = pal_igv(palette=c("default"),alpha=1)(17)
color=pal_ucscgb(palette=c("default"),alpha=1)(12)
col=color[1:12]
chr<-cbind(chr,col)
rownames(chr)<-chr[,1]

par(mar=c(4,4,2,2))
plot(efr1[,1],ylim=c(-.2,.4),type='n',xaxt='n',
     ylab="Deviation from expected allele frequencies due to admixture",bty='l')
for(i in 1:dim(efr1)[[2]]){
  lines(efr1[,i],ylim=c(0,.4),lwd=1.5,col=chr[colnames(efr1)[i],2])
}
axis(side=1,at=1:7,labels=c(rownames(efr1)))
abline(h=1,lwd=3,lty=2)
legend("topright",legend=c(chr[,1]),col=c(chr[,2]),pch=20,cex=1)

```

#Introgression models

```{r}

cl_mig_stagSweeps = readRDS("~/analysis/data/intro_models/compLikelihood_mig_stagSweeps.RDS")
cl_neutral = readRDS("~/analysis/data/intro_models/compLikelihood_neutral.RDS")
cl_sv = readRDS("~/analysis/data/intro_models/compLikelihood_stdVar.RDS")

sels = readRDS("~/analysis/data/intro_models/sels.RDS")
times = readRDS("~/analysis/data/intro_models/times.RDS")
gs = readRDS("~/analysis/data/intro_models/gs.RDS")


maxCL_mig_stagSweeps.sels = sapply(1 : length(sels), function(i) max(unlist(cl_mig_stagSweeps[[i]])))
maxCL_sv.sels = sapply(1 : length(sels), function(i) max(unlist(cl_sv[[i]])))

cl_mig_stagSweeps_byTime = lapply(1 : length(times), function(time) lapply(1 : length(sels), function(sel) lapply(1 : length(gs), function(g) cl_mig_stagSweeps[[sel]][[g]][[time]])))
maxCL_mig_stagSweeps.times = sapply(1 : length(times), function(i) max(unlist(cl_mig_stagSweeps_byTime[[i]])))

sels18_scaled = (sels[18:31] - sels[18]) / (sels[31] - sels[18]) #get last sels and put on (0,1) scale
times18_scaled = (times[1:18] - times[1]) / (times[18] - times[1]) #get last times and put on (0,1) scale

yMin = min(c(maxCL_mig_stagSweeps.sels, maxCL_sv.sels) - cl_neutral)
yMax = max(c(maxCL_mig_stagSweeps.sels, maxCL_sv.sels) - cl_neutral)

jpeg("~/backup/UCD/Projects/Adaptation + Introgression/draft/images/intro_models.jpeg",width=600,height=400)
par(oma = c(1,1.5,2,1.5),mar=c(3,3,3,3),mgp=c(1,2,0))
plot(sels18_scaled, maxCL_mig_stagSweeps.sels[18:31] - cl_neutral, 
     cex.axis = 1.3, ylab = "", ylim = c(4.8e5, yMax), 
     type = "l", col = "red", xlim = c(0, 1), xaxt = "none", xlab = "", lwd = 6, cex.lab = 1.1)
box(lwd=6)
lines(sels18_scaled, maxCL_sv.sels[18:31] - cl_neutral, col = "red", lwd = 6, lty = 2)
axis(1, at = seq(0, 1, length.out = 6), labels = seq(0.5, 1, length.out = 6), col = "red", lwd = 6, cex.axis = 2.8)
lines(times18_scaled, maxCL_mig_stagSweeps.times[1:18] - cl_neutral, col = "plum2", lwd = 6, lty = 1)
axis(3, lwd = 6, at = seq(0, 1, length.out = 6), labels = seq(times[1], times[18], length.out = 6), col = "plum2", cex.axis = 2.8)

#legend("bottomright", lty = c(1,2), legend = c("Introgression", "ILS"), lwd = 6)
#mtext(line = 3, side = 1, text = "selection coefficient", cex = 1.3)
#mtext(line = 3, side = 3, text = "time between introgression and selection (generations)", cex = 1.1)
#axis 1 label = Composite log-likelihood (model - neutral)
dev.off()

```

##Introgression
###Plotting dxy

```{r}
library(stringr)
library(dplyr)
library(gtools)
library('naturalsort')
load("~/analysis/scripts/introgression/dxyscan.Rdata") #loading data into R


subw<-dxyscan[,"keep"]==TRUE
dxy<-dxyscan[subw,1:9]

ord<-mixedorder(dxy$chr)
dxyt<-dxy[ord,]

dxy2<-dxyt %>% filter(str_detect(chr,"chr"))

col<-c()
for(i in 1:3){
  col[i]<-quantile(dxy2[,i+6],probs=0.005)
}

chr16<-dxy2 %>% filter(str_detect(chr,"chr16"))#checking out chr16
ord<-order(chr16[,"BB"],decreasing=FALSE) #ordering them so I can remove the crappy scaffold
crap<-str_detect(chr16$scaf,"NW_012224891.1")
crap2<-str_detect(chr16$scaf,"NW_012224806.1")
ord<-order(chr16[!crap,"BB"],decreasing=FALSE) #ordering them so I can remove the crappy scaffold


crappy<-str_detect(dxy2$scaf,"NW_012224891.1")
dxy3<-dxy2[!crappy,]
crappy2<-str_detect(dxy3$scaf,"NW_012224806.1")
dxy4<-dxy3[!crappy2,]

dxy4$chr<-factor(dxy4$chr,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))

#tiff("~/analysis/data/introgression/introgression.tiff",width=1200,height=600)
palette(c("grey40","grey80"))
par(mfrow=c(3,1),mar=c(2,4,2,0))
plot(dxy4[,"BB"],pch=20,cex=1,col=ifelse(dxy4[,"BB"]<col[2],"red",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.021),cex.axis=2.5)
plot(dxy4[,"VB"],pch=20,cex=1,col=ifelse(dxy4[,"VB"]<col[1],"red",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.021),cex.axis=2.5)
plot(dxy4[,"PB"],pch=20,cex=1,col=ifelse(dxy4[,"PB"]<col[3],"red",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.021),cex.axis=2.5)
#dev.off()
``` 

## Deletion plotting for both species

```{r}
# install.packages('viridis')
# install.packages('dplyr')
# install.packages('magrittr')
# install.packages('Rphylip')
# install.packages('ape')
# install.packages('stringr')

library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)

source("~/analysis/scripts/depth/pullgenos.r")
#source("~/analysis/scripts/depth/pullgenos.phased.r")

gts<-pullgenos("chr1:650000-900000")
#hap<-pullgenos.phased("chr1:650000-900000")
colnames(gts)[1] <- "pos"
dep<-read.table("~/analysis/data/depth/NW_012234474.1_550000-800000.depth.txt.gz",stringsAsFactors=FALSE)
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
mat<-read.table("~/analysis/data/plink/popcolors.txt",stringsAsFactors=FALSE,sep="\t")
pops <- gsub("-.*","",sexscore[,1])
popord <- c(grep("BB",sexscore$sample),grep("VB",sexscore$sample),grep("PB",sexscore$sample),grep("SJ",sexscore$sample),
            grep("BNP",sexscore$sample),grep("SP",sexscore$sample),grep("GB",sexscore$sample))
bbo<-grep("BB",sexscore$sample)
vbo<-grep("VB",sexscore$sample)
pbo<-grep("PB",sexscore$sample)
sjo<-grep("SJ",sexscore$sample)
bnpo<-grep("BNP",sexscore$sample)
spo<-grep("SP",sexscore$sample)
gbo<-grep("GB",sexscore$sample)


##deletion boundaries:
  #approximate break points:740000-800000
  #will use a conservative window that doesn't include a little spike in coverage: 760000-800000

#no deletion
nodel<-dep[,2]>810000&dep[,2]<890000
del<-dep[,2]>760000&dep[,2]<800000

scalevec <- colSums(dep[nodel,-c(1,2)])/(sum(nodel))
scalevec2<- colSums(dep[del,-c(1,2)])/sum(del)

copies_per_ind <- data.frame(cbind(n_copies=rep(2,288),pop=gsub("-.*","",sexscore[,1])),stringsAsFactors=FALSE)
rownames(copies_per_ind) <- colnames(gts)[-1]

#my alternative

bbcopy<-t(t(dep[del,bbo+2])/scalevec[bbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

vbcopy<-t(t(dep[del,vbo+2])/scalevec[vbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

pbcopy<-t(t(dep[del,pbo+2])/scalevec[pbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

sjcopy<-t(t(dep[del,sjo+2])/scalevec[sjo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

bnpcopy<-t(t(dep[del,bnpo+2])/scalevec[bnpo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

spcopy<-t(t(dep[del,spo+2])/scalevec[spo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

gbcopy<-t(t(dep[del,gbo+2])/scalevec[gbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

plot(bbcopy,col="black",ylim=c(0,50000),xlim=c(1,50),pch=20,cex=1)
plot(vbcopy,col="grey",pch=20,cex=1)
plot(pbcopy,col="red",pch=20,cex=1)
plot(sjcopy,col="darkorange",pch=20,cex=1)
plot(bnpcopy,col="gold",pch=20,cex=1)
plot(spcopy,col="cyan",pch=20,cex=1)
plot(gbcopy,col="blue",pch=20,cex=1)

msp<-mean(spcopy[1:47])
ssp<-sd(spcopy[1:47])

abline(h=msp-2*ssp,lty=2,lwd=3,col="black")
abline(h=10000,lty=2,lwd=3,col="grey")


###Counting the copies

bbnum<-t(t(dep[del,bbo+2])/scalevec[bbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,bbo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,18),rep(1,5),rep(0,1))
  )

copies_per_ind[bbnum[,1],1]<-bbnum[,2]

vbnum<-t(t(dep[del,vbo+2])/scalevec[vbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,vbo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,38),rep(1,10),rep(0,1))
  )

copies_per_ind[vbnum[,1],1]<-vbnum[,2]

pbnum<-t(t(dep[del,pbo+2])/scalevec[pbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,pbo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,21),rep(1,22),rep(0,4))
  )

copies_per_ind[pbnum[,1],1]<-pbnum[,2]

sjnum<-t(t(dep[del,sjo+2])/scalevec[sjo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,sjo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,1),rep(1,4),rep(0,19))
  )

copies_per_ind[sjnum[,1],1]<-sjnum[,2]

bnpnum<-t(t(dep[del,bnpo+2])/scalevec[bnpo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,bnpo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,5),rep(0,43))
  )

copies_per_ind[bnpnum[,1],1]<-bnpnum[,2]

spnum<-t(t(dep[del,spo+2])/scalevec[spo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,spo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,0),rep(0,48))
  )

copies_per_ind[spnum[,1],1]<-spnum[,2]

gbnum<-t(t(dep[del,gbo+2])/scalevec[gbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (gts[,gbo+1])[,.] %>%
  colnames() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,1),rep(0,47))
  )

copies_per_ind[gbnum[,1],1]<-gbnum[,2]

copies_per_ind[,1] <- as.numeric(copies_per_ind[,1])


# table(copies_per_ind[,c(1,2)]) %>% 
#   (function(x){as.array(x[,c(3,6,2,5,4,7,1)])}) %>% 
#   (function(x){barplot(x,beside=TRUE,col=c("darkolivegreen1","chartreuse3","darkgreen"),
#                        ylab='',cex.axis = 2.5,cex.names = 1.5)})
par(mfrow=c(1,1),mar=c(2,4,2,4))
copies<-as.array(table(copies_per_ind[,c(1,2)]) %>% 
                (function(x){x[,c(3,6,2,5,4,7,1)]}) )
copies.prop<-prop.table(copies,2)*100 
barplot(copies.prop,beside=TRUE,col=c("darkolivegreen1","chartreuse3","darkgreen"),
       ylab='',cex.axis = 2.2,cex.names = 1.5)

# legend("topright",legend=c("wt","delHet","delHom"),pch=20,cex=1.2,col=c("blue","red","pink","green","lightgrey","grey50","black"),
#        x.intersp = 0.4,y.intersp = .7)

###smoothing vector function

subsmooth <- function(vec,by=10,width=1000){
  
  len <- length(vec)
  subl <- seq(from=by,to=len,by=by)
  submax <- length(subl)
  width <- width/2
  test <- vec[subl]
  
  for(i in 1:submax){
    
    j <- i - width
    k <- i + width
    if(j < 1) {j <- 1}
    if(k > submax) {k <- submax}
    test[i] <- mean(test[j:k],na.rm=TRUE)
  }
  
  return(test)
  
}


###smoothing pop coverage

depsub <- as.data.frame(apply(dep[,-c(1,2)],MAR=2,FUN=subsmooth,by=20,width=500))
jump<-dep[seq(from=20,to=dim(dep)[1],by=20),2]
depsub <- cbind("Chr1sub",jump,depsub)

par(mfrow=c(7,1),mar=c(2,4,1.5,0.5))


bb <- grep("BB",sexscore$sample)
t(t(depsub[,bbo+2])/scalevec[bbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(bbo)),ylab="BB")

vb <- grep("vb",sexscore$sample)
t(t(depsub[,vbo+2])/scalevec[vbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(vbo)),ylab="VB")

pb <- grep("pb",sexscore$sample)
t(t(depsub[,pbo+2])/scalevec[pbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(pbo)),ylab="PB")

sj <- grep("sj",sexscore$sample)
t(t(depsub[,sjo+2])/scalevec[sjo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(sjo)),ylab="SJ")

bnp <- grep("bnp",sexscore$sample)
t(t(depsub[,bnpo+2])/scalevec[bnpo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(bnpo)),ylab="BNP")

sp <- grep("sp",sexscore$sample)
t(t(depsub[,spo+2])/scalevec[spo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(spo)),ylab="SP")

gb <- grep("gb",sexscore$sample)
t(t(depsub[,gbo+2])/scalevec[gbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(gbo)),ylab="GB")

par(mfrow=c(2,1),mar=c(2,4,1.5,0.5))

###Sex

f <- grep("F",sexscore$sex)
t(t(depsub[,f+2])/scalevec[f]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(f)),ylab="F")


m <- grep("M",sexscore$sex)
t(t(depsub[,m+2])/scalevec[m]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(m)),ylab="M")


####representative graphs
#make representative coverage figures for three individuals,yes/het/no duplication
#264 - homozygous BB
#277 - heterozygous SJ
#19 - no deletion SP
par(mfrow=c(3,1),mar=c(2,2,1.5,0.5))

ind <- 264
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")

ind <- 277
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")

ind <- 19
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")


##Alternative plot
ind1 <- 264
ind2 <- 277
ind3 <- 19
par(mfrow=c(1,1),mar=c(4,4,1.5,0.5))
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],subsmooth(dep[,ind1])/scalevec[ind1-2],pch=20,cex=.3,col="black",ylim=c(0,2.2),
     ylab="Smoothed region coverage",xlab="Location on chromosome1")
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind2])/scalevec[ind2-2],pch=20,cex=.3,col="firebrick2")
points(dep[subl,2],subsmooth(dep[,ind3])/scalevec[ind3-2],pch=20,cex=.3,col="cadetblue3")

legend("bottomright",lty=2,lwd=2,legend=c("wt/wt S2","del/wt IH1","del/del R1"),col=c("cadetblue3","firebrick2","black"),cex=1.4,
       x.intersp = .7,y.intersp = 1)
abline(v=c(729500,806000),lty=2,lwd=2,col="purple")
abline(v=c(728500,730500,765000,767000,805000,807000),lty=2,lwd=2,col="purple")


###returns population frequency given pop,sex,data

freq <- function(df,pop){
  vec <-grepl(pop,colnames(df))
  apply(df[,vec],
        MAR=1,
        FUN=function(x){
          sum(x,na.rm=TRUE)/sum(!is.na(x))/2
        }
  )
}

###make a tree!

Fpopfreqs <- cbind(
  freq(gts,"BB"),
  freq(gts,"VB"),
  freq(gts,"PB"),
  freq(gts,"SJ"),
  freq(gts,"BNP"),
  freq(gts,"SP"),
  freq(gts,"GB")
)
colnames(Fpopfreqs) <- c("BB","VB","PB","SJ","BNP","SP","GB")
Fpopfreqs <- Fpopfreqs[which(rowSums(is.na(Fpopfreqs))==0),]

#using contml
tr <- Rcontml(X=t(Fpopfreqs),path="~/phylip-3.696/exe")

#already ran bootstraps, don't re-run unless necessary. 
#trboot <- boot.phylo(tr,t(Fpopfreqs),FUN=function(x){Rcontml(X=x,path="~/phylip-3.696/exe")},trees=TRUE)

#for some reason boot.phylo calculates BP wrong. 
plot(tr,type="unrooted",show.tip.label=FALSE)
# nodelabels(trboot$BP)
popord <- c(3, 4, 5, 6, 7, 2, 1)
popcol <- c("black","grey","red","darkorange","gold","cyan","blue")
popnames <- c("BB","VB","PB","SJ","BNP","SP","GB")
tiplabels(pch=20,col=popcol[popord],cex=6)
legend("topright",legend=popnames,col=popcol,pch=20,cex=1)

###


trN <- Rgendist(t(Fpopfreqs),path="~/phylip-3.696/exe/") %>% 
  Rneighbor(.,path="~/phylip-3.696/exe/")


trbootN <- boot.phylo(trN,t(Fpopfreqs),FUN=function(x){
  Rgendist(t(Fpopfreqs),path="~/phylip-3.696/exe/") %>% 
    Rneighbor(.,path="~/phylip-3.696/exe/")
},trees=TRUE)

plot(trN,type="unrooted")
nodelabels(trbootN$BP)

```

##Physiology data

###Starting with CYP1A activity

```{r}

#loading in the file----
setwd("~/backup/Elias/Baylor/Papers/11. Gradient and Introgression - DRAFT/Deformity and EROD")

cyp1a<-read.csv("PCB_erod_0.1ppt.csv",header=T)

library(ggplot2)
library(dplyr)

#dotplot of merged pop data----
d<-ggplot(cyp1a,aes(x=sens,y=(resp)/100,fill=sens)) +
  #geom_violin(trim=TRUE, fill="white") +
  geom_dotplot(binaxis='y',stackdir='center',binwidth=.4,
               stackratio=.3,dotsize=35) +
  ggtitle("CYP1A activity at 0.1ppb PCB126")+
  theme_classic()+
  scale_fill_manual(values=c(S="cadetblue3",IL="gold",IH="firebrick2",R="black")) +
  scale_x_discrete(limits=c("S","IL","IH","R"))
d.labs<-d+labs(y="",x="")
larger.thicker<-element_line(color="black",size=3)
d.lines<-d.labs + theme(axis.line.y=larger.thicker,axis.line.x=larger.thicker)
larger.text<-element_text(color="black",size=30)
d.lines+theme(axis.text.y=larger.text)

#boxplot for sensitivity level----
boxplot(cyp1a[,"resp"]~cyp1a[,"sens"],log="y",yaxt='n',
        at=c(2,3,1,4),col=c("firebrick2","gold","black","cadetblue3"),
        cex.axis=1,outline=FALSE,range=TRUE)
box(lwd=5,bty="l")
ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))
axis(side=2, at=c(10, 100, 1000, 10000), labels=labels,las=1)

#boxplot of all pop data----
cyp1a$pop2<-factor(cyp1a$pop, levels=c("BB","VB","PB","SJ","BNP","CB","FP","HP","PG","FB","SP","GB"))

boxplot(cyp1a[,"resp"]~cyp1a[,"pop2"],log="y",yaxt='n',
        col=c(rep("black",3),rep("firebrick2",3),rep("gold",3),rep("cadetblue3",3)),
        cex.axis=1,outline=FALSE,range=TRUE)
box(lwd=5,bty="l")

ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))
axis(side=2, at=c(10, 100, 1000, 10000), labels=labels,las=1)

#USE Violin plot of all pop data----

ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))

ggplot(cyp1a,
       aes(x=pop2,y=log10(resp),fill=pop2,color=pop2))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c(rep("black",3),rep("firebrick2",3),rep("gold",3),rep("cadetblue3",3)))+
  scale_color_manual(values=c(rep("grey40",3),rep("black",9)))+
  geom_jitter(shape=16,size=3,position=position_jitter(.2))+
  theme_classic()+
  labs(y='',x='')+
  theme(axis.line.y=element_line(color="black",size=3),axis.line=element_line(color="black",size=3))+
  scale_y_continuous(labels=labels,breaks=c(1,2,3,4))+
  theme(axis.text.y=element_text(color="black",size=40))


##LM

cplm=lm(resp~sens,cyp1a)
summary(cplm)

#plotting histogram----
m<-ggplot(cyp1a,aes(x=resp,fill=sens)) + 
  geom_histogram(alpha=.4,aes(y=..density..),position="identity") + 
  ggtitle("CYP1A activity at 0.1ppb PCB126")+
  theme_bw() +
  scale_fill_manual(values=c(S="cadetblue3",IL="gold",IH="firebrick",R="black"))
m

```

